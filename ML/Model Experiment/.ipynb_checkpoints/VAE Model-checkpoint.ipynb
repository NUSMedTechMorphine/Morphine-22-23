{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "738e729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange\n",
    "from time import time\n",
    "\n",
    "from sklearn.covariance import MinCovDet\n",
    "from scipy.stats import chi2\n",
    "\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing, linear_model\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from sklearn.preprocessing import minmax_scale, OneHotEncoder\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Input, Dense, Reshape, Concatenate, Flatten, Lambda, Reshape, Dropout\n",
    "from keras.losses import MeanSquaredError as mse\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dfc24e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fall_simulation',\n",
       " 'fall_simulation2',\n",
       " 'fall_simulation3',\n",
       " 'fall_simulation_2.csv',\n",
       " 'fall_simulation_3.csv',\n",
       " 'trial_data_1',\n",
       " 'trial_data_1.csv',\n",
       " 'trial_data_2',\n",
       " 'trial_data_2.csv',\n",
       " 'trial_data_3',\n",
       " 'trial_data_3.csv',\n",
       " 'trial_data_4',\n",
       " 'trial_data_4.csv',\n",
       " 'trial_data_5',\n",
       " 'trial_data_5.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASETS_PATH = \"C:/Users/ernest.liu/Documents/git/Morphine-22-23/ML/Datasets/19-01-2023/\"\n",
    "os.chdir(DATASETS_PATH)\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf4816e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trial_data_1.csv', 'trial_data_2.csv', 'trial_data_3.csv', 'trial_data_4.csv', 'trial_data_5.csv']\n",
      "['fall_simulation_2.csv', 'fall_simulation_3.csv']\n"
     ]
    }
   ],
   "source": [
    "adl_files = [file_name for file_name in os.listdir() if \".csv\" in file_name and \"trial\" in file_name]\n",
    "fall_files = [file_name for file_name in os.listdir() if \".csv\" in file_name and \"fall\" in file_name]\n",
    "\n",
    "print(adl_files)\n",
    "print(fall_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd65722",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data_1 = pd.read_csv(DATASETS_PATH+'trial_data_1.csv').iloc[:,1:]\n",
    "trial_data_2 = pd.read_csv(DATASETS_PATH+'trial_data_2.csv').iloc[:,1:]\n",
    "trial_data_3 = pd.read_csv(DATASETS_PATH+'trial_data_3.csv').iloc[:,1:]\n",
    "trial_data_4 = pd.read_csv(DATASETS_PATH+'trial_data_4.csv').iloc[:,1:]\n",
    "trial_data_5 = pd.read_csv(DATASETS_PATH+'trial_data_5.csv').iloc[:,1:]\n",
    "\n",
    "fall_simulation_2 = pd.read_csv(DATASETS_PATH+'fall_simulation_2.csv').iloc[:,1:]\n",
    "fall_simulation_3 = pd.read_csv(DATASETS_PATH+'fall_simulation_3.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "189b1c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only take in accelerometer and gyroscope data\n",
    "trial_data_1 = trial_data_1[['Ax','Ay','Az','gx','gy','gz']]\n",
    "trial_data_2 = trial_data_2[['Ax','Ay','Az','gx','gy','gz']]\n",
    "trial_data_3 = trial_data_3[['Ax','Ay','Az','gx','gy','gz']]\n",
    "trial_data_4 = trial_data_4[['Ax','Ay','Az','gx','gy','gz']]\n",
    "trial_data_5 = trial_data_5[['Ax','Ay','Az','gx','gy','gz']]\n",
    "\n",
    "fall_simulation_2 = fall_simulation_2[['Ax','Ay','Az','gx','gy','gz']]\n",
    "fall_simulation_3 = fall_simulation_3[['Ax','Ay','Az','gx','gy','gz']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63007455",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([trial_data_1, trial_data_2, trial_data_3, trial_data_4, trial_data_5]).reset_index(drop=True)\n",
    "test_data = pd.concat([fall_simulation_2, fall_simulation_3]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c8bf526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EDA\n",
    "plt.hist(np.abs(train_data.Ay), bins=100, alpha=0.5, density=True)\n",
    "plt.hist(np.abs(test_data.Ay), bins=100, alpha=0.5, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c7465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5790b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79deb44d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e37a0e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7044129",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_norm_presplit = scaler.transform(train_data)\n",
    "test_data_norm = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da93a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ratio = 0.2\n",
    "valid_indices = sorted(random.sample(list(range(train_data_norm_presplit.shape[0])), round(train_data_norm_presplit.shape[0] * valid_ratio)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4601de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = train_data.iloc[valid_indices, :].reset_index(drop = True)\n",
    "valid_data_norm = train_data_norm_presplit[valid_indices]\n",
    "train_data_norm = np.delete(train_data_norm_presplit, valid_indices, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50264422",
   "metadata": {},
   "source": [
    "## Mahalanobis Distance Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881a3204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance matrix\n",
    "# covariance = np.cov(train_data, rowvar=False)\n",
    "\n",
    "start_time = time()\n",
    "cov = MinCovDet().fit(train_data_norm)\n",
    "end_time = time()\n",
    "print(f\"Time elapsed: {(end_time - start_time)/60} minutes\")\n",
    "covariance = cov.covariance_\n",
    "\n",
    "covariance = np.cov(train_data_norm, rowvar=False)\n",
    "\n",
    "# Covariance matrix power of -1\n",
    "covariance_pm1 = np.linalg.matrix_power(covariance, -1)\n",
    "\n",
    "# Center point\n",
    "centerpoint = np.mean(train_data_norm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distances between center point and \n",
    "distances = []\n",
    "for i, val in enumerate(train_data_norm):\n",
    "    p1 = val\n",
    "    p2 = centerpoint\n",
    "    distance = (p1-p2).T.dot(covariance_pm1).dot(p1-p2)\n",
    "    distances.append(distance)\n",
    "distances = np.array(distances)\n",
    "\n",
    "# Cutoff (threshold) value from Chi-Sqaure Distribution for detecting outliers \n",
    "cutoff_threshold = 0.99\n",
    "cutoff = chi2.ppf(cutoff_threshold, train_data_norm.shape[1])\n",
    "\n",
    "# Index of outliers\n",
    "outlierIndexes = np.where(distances > cutoff)\n",
    "\n",
    "print('--- Index of Outliers ----')\n",
    "print(outlierIndexes)\n",
    "print(f\"There are {len(outlierIndexes[0])} outliers identified\")\n",
    "\n",
    "print('--- Observations found as outlier -----')\n",
    "print(train_data_norm[distances > cutoff, :])\n",
    "\n",
    "train_data_norm = np.delete(train_data_norm, outlierIndexes, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b3abc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d0de86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2879cdbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8342416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bb8b713",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0033e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_dim = 2\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(latent_space_dim,), mean=0., stddev=1.) # stddev is set to 0.1 in this post: https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "    return_value = z_mean + K.exp(z_log_sigma) * epsilon\n",
    "    #print(z_mean)\n",
    "    \n",
    "    return return_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad4437c",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8279e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((6,))\n",
    "layer1 = Dense(6, activation = 'relu')(inputs)\n",
    "layer2 = Dense(200, activation = 'relu')(layer1) # Changed from 3\n",
    "layer3 = Dense(100, activation = 'relu')(layer2) # Changed from 3\n",
    "layer4 = Dense(60, activation = 'relu')(layer3)\n",
    "layer5 = Dense(30, activation = 'relu')(layer4)\n",
    "z_mean = Dense(latent_space_dim)(layer5)\n",
    "z_log_sigma = Dense(latent_space_dim)(layer5)\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_sigma], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9099e7",
   "metadata": {},
   "source": [
    "### Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc8098",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_input1 = keras.Input(shape=(latent_space_dim,))\n",
    "sampler_input2 = keras.Input(shape=(latent_space_dim,))\n",
    "latent_sample = Lambda(sampling, output_shape = (latent_space_dim,))([sampler_input1, sampler_input2])\n",
    "sampler = keras.Model([sampler_input1, sampler_input2], latent_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7804bf1",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cf6b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_space_dim,))\n",
    "layer6 = Dense(20, activation = 'relu')(latent_inputs)\n",
    "layer7 = Dense(30, activation = 'relu')(layer6)\n",
    "layer8 = Dense(50, activation = 'relu')(layer7)\n",
    "layer9 = Dense(100, activation = 'relu')(layer8)\n",
    "layer10 = Dense(200, activation = 'relu')(layer9)\n",
    "decoder_outputs = Dense(6, activation = 'sigmoid')(layer10)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1508701b",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f9e962",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "    def __init__(self, encoder, sampler, decoder, beta = 1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.sampler = sampler\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_sigma = self.encoder(data)\n",
    "            z_log_var = 2 * z_log_sigma\n",
    "            z = self.sampler([z_mean, z_log_var])\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    def test_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            #print(f\"Ran. data: {data}\")\n",
    "            data = data[0]\n",
    "\n",
    "        z_mean, z_log_sigma = self.encoder(data)\n",
    "        z_log_var = 2 * z_log_sigma\n",
    "        z = self.sampler([z_mean, z_log_var])\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(kl_loss)\n",
    "        total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def call(self, data):\n",
    "        z_mean, z_log_sigma = self.encoder(data)\n",
    "        z_log_var = 2 * z_log_sigma\n",
    "        z = self.sampler([z_mean, z_log_var])\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(kl_loss)\n",
    "        total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        self.add_metric(kl_loss, name='kl_loss', aggregation='mean')\n",
    "        self.add_metric(total_loss, name='total_loss', aggregation='mean')\n",
    "        self.add_metric(reconstruction_loss, name='reconstruction_loss', aggregation='mean')\n",
    "        return reconstruction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deded5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, sampler, decoder, beta = 0.01)\n",
    "vae.compile(optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79db1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "history = vae.fit(x = train_data_norm, y = train_data_norm, # Changed from train_data_norm \n",
    "                  epochs = 1000,\n",
    "                  shuffle = True,\n",
    "                  batch_size = 32,\n",
    "                  workers = 8,\n",
    "                  validation_data = (valid_data_norm, valid_data_norm), # Changed from valid_data_norm\n",
    "                  callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedf11a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label = 'Training Loss')\n",
    "plt.plot(history.history['val_loss'], label = 'Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ea548",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = vae.predict(train_data_norm)\n",
    "test_predictions = vae.predict(test_data_norm)\n",
    "valid_predictions = vae.predict(valid_data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6686659",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"vae_fixed_loss_beta_0_01\"\n",
    "# os.chdir(\"C:/Users/ernest.liu/Documents/git/Morphine-22-23/ML/Model/weights/\")\n",
    "# vae.save_weights(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0c62db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training MAE: {np.sum(np.abs(train_data_norm - train_predictions))/(train_data_norm.shape[0] * train_data_norm.shape[1])}\")\n",
    "print(f\"Testing MAE (Anomalous Data): {np.sum(np.abs(test_data_norm - test_predictions))/(test_data_norm.shape[0] * test_data_norm.shape[1])}\")\n",
    "print(f\"Validation MAE (Normal Data): {np.sum(np.abs(valid_data_norm - valid_predictions))/(valid_data_norm.shape[0] * valid_data_norm.shape[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2186634",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mae = np.sum(np.abs(train_data_norm - train_predictions), axis = 1)\n",
    "plt.hist(train_mae, bins = 20)\n",
    "plt.title(\"Training Dataset\")\n",
    "plt.xlabel(\"Reconstruction Error (MAE)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d99ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_mae = np.sum(np.abs(valid_data_norm - valid_predictions), axis = 1)\n",
    "plt.hist(valid_mae, bins = 20)\n",
    "plt.title(\"Validation (Normal Samples) Dataset\")\n",
    "plt.xlabel(\"Reconstruction Error (MAE)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995dbc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae = np.sum(np.abs(test_data_norm - test_predictions), axis = 1)\n",
    "plt.hist(test_mae, bins = 20)\n",
    "plt.title(\"Testing (Anomalous) Dataset\")\n",
    "plt.xlabel(\"Reconstruction Error (MAE)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e64acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold = np.quantile(valid_mae, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ea2963",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110df665",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"mae\"] = np.sum(np.abs(scaler.transform(train_data) - vae.predict(scaler.transform(train_data))), axis = 1)\n",
    "train_data[\"is_anomalous\"] = train_data.mae > best_threshold\n",
    "\n",
    "test_data[\"mae\"] = test_mae\n",
    "test_data[\"is_anomalous\"] = test_mae > best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a807a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b18d59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test_data.index, test_data.mae, s = 0.2)\n",
    "plt.axhline(y=best_threshold, color='r', linestyle='-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0613ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_data.index, train_data.mae, s = 0.2)\n",
    "plt.axhline(y=best_threshold, color='r', linestyle='-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c1f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(test_data.is_anomalous)/test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34137a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(train_data.is_anomalous)/train_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff53e8",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c33529fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_dim = 2\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(latent_space_dim,), mean=0., stddev=1.) # stddev is set to 0.1 in this post: https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "    return_value = z_mean + K.exp(z_log_sigma) * epsilon\n",
    "    #print(z_mean)\n",
    "    \n",
    "    return return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56b34417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 6)            42          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 200)          1400        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 100)          20100       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 60)           6060        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 30)           1830        ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 2)            62          ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 2)            62          ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29,556\n",
      "Trainable params: 29,556\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input((6,))\n",
    "layer1 = Dense(6, activation = 'relu')(inputs)\n",
    "layer2 = Dense(200, activation = 'relu')(layer1) # Changed from 3\n",
    "layer3 = Dense(100, activation = 'relu')(layer2) # Changed from 3\n",
    "layer4 = Dense(60, activation = 'relu')(layer3)\n",
    "layer5 = Dense(30, activation = 'relu')(layer4)\n",
    "z_mean = Dense(latent_space_dim)(layer5)\n",
    "z_log_sigma = Dense(latent_space_dim)(layer5)\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_sigma], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55c2c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_input1 = keras.Input(shape=(latent_space_dim,))\n",
    "sampler_input2 = keras.Input(shape=(latent_space_dim,))\n",
    "latent_sample = Lambda(sampling, output_shape = (latent_space_dim,))([sampler_input1, sampler_input2])\n",
    "sampler = keras.Model([sampler_input1, sampler_input2], latent_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82494e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 20)                60        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 30)                630       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 50)                1550      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 6)                 1206      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,746\n",
      "Trainable params: 28,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_space_dim,))\n",
    "layer6 = Dense(20, activation = 'relu')(latent_inputs)\n",
    "layer7 = Dense(30, activation = 'relu')(layer6)\n",
    "layer8 = Dense(50, activation = 'relu')(layer7)\n",
    "layer9 = Dense(100, activation = 'relu')(layer8)\n",
    "layer10 = Dense(200, activation = 'relu')(layer9)\n",
    "decoder_outputs = Dense(6, activation = 'sigmoid')(layer10)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3350a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "    def __init__(self, encoder, sampler, decoder, beta = 1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.sampler = sampler\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_sigma = self.encoder(data)\n",
    "            z_log_var = 2 * z_log_sigma\n",
    "            z = self.sampler([z_mean, z_log_var])\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    def test_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            #print(f\"Ran. data: {data}\")\n",
    "            data = data[0]\n",
    "\n",
    "        z_mean, z_log_sigma = self.encoder(data)\n",
    "        z_log_var = 2 * z_log_sigma\n",
    "        z = self.sampler([z_mean, z_log_var])\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(kl_loss)\n",
    "        total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def call(self, data):\n",
    "        z_mean, z_log_sigma = self.encoder(data)\n",
    "        z_log_var = 2 * z_log_sigma\n",
    "        z = self.sampler([z_mean, z_log_var])\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(kl_loss)\n",
    "        total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        self.add_metric(kl_loss, name='kl_loss', aggregation='mean')\n",
    "        self.add_metric(total_loss, name='total_loss', aggregation='mean')\n",
    "        self.add_metric(reconstruction_loss, name='reconstruction_loss', aggregation='mean')\n",
    "        return reconstruction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34bd3cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, sampler, decoder, beta = 0.01)\n",
    "vae.compile(optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74da16be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1c356510a30>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"C:/Users/ernest.liu/Documents/git/Morphine-22-23/ML/Model/weights/\")\n",
    "model_name = \"vae_fixed_loss_beta_0_01\"\n",
    "vae.load_weights(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae0d295b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3320/3320 [==============================] - 4s 1ms/step\n",
      "67/67 [==============================] - 0s 1ms/step\n",
      "830/830 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions = vae.predict(train_data_norm)\n",
    "test_predictions = vae.predict(test_data_norm)\n",
    "valid_predictions = vae.predict(valid_data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "516b59e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_mae = np.sum(np.abs(valid_data_norm - valid_predictions), axis = 1)\n",
    "best_threshold = np.quantile(valid_mae, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7be0622f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.686759037392612"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0af01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fb4972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca69a943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5854156 , 0.46265173, 0.41917389, 0.61670481, 0.43592677,\n",
       "        0.52402746],\n",
       "       [0.59229985, 0.46685341, 0.41483937, 0.61441648, 0.46681922,\n",
       "        0.51716247],\n",
       "       [0.59561448, 0.47432306, 0.4145844 , 0.61098398, 0.5       ,\n",
       "        0.51029748],\n",
       "       ...,\n",
       "       [0.50713921, 0.49112979, 0.42172361, 0.42791762, 0.85583524,\n",
       "        0.36498856],\n",
       "       [0.50739419, 0.48832866, 0.42299847, 0.43135011, 0.85469108,\n",
       "        0.36384439],\n",
       "       [0.50509944, 0.49112979, 0.42554819, 0.43478261, 0.85354691,\n",
       "        0.36498856]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ad0a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(scaler, open('scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d64b8f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ernest.liu\\\\Documents\\\\git\\\\Morphine-22-23\\\\ML\\\\Model\\\\weights'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ed64f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f71e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93347fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b663fe60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5e24e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227b53f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c4bcad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0026724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/ernest.liu/Documents/git/Morphine-22-23/ML/Docker/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86499aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import db\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Connection to Firebase\n",
    "cred_obj = firebase_admin.credentials.Certificate(\"../Morphine2.json\")\n",
    "default_app = firebase_admin.initialize_app(cred_obj, {\n",
    "  'databaseURL':'https://morphine-64cdd-default-rtdb.asia-southeast1.firebasedatabase.app/'\n",
    "  })\n",
    "USERS_DATA = db.reference(\"/Users Data/Token UID:XvIeVwC7M0QN0qW15FNYO2e5BJ93\")\n",
    "FIREBASE_PREDICTION_PATH = db.reference(\"/Users Data/Token UID:XvIeVwC7M0QN0qW15FNYO2e5BJ93/Split Circuit/MPU6050/MPU6050 Fall/\")\n",
    "\n",
    "# Process GPS Data\n",
    "GPS_KEYWORDS_LIST = ['Latitude: ', '(*10^-7) Longitude: ', '(*10^-7) Altitude: ', '(mm) Satellite-in-view: ', 'timing for this set: ']\n",
    "GPS_KEYWORDS_LENGTH = [len(keyword) for keyword in GPS_KEYWORDS_LIST]\n",
    "\n",
    "def process_gps_datapoints(gps_datapoints):\n",
    "    \"\"\"\n",
    "    gps_datapoints = gps_data['GPS Datapoints']\n",
    "    \"\"\"\n",
    "    gps_datapoints = gps_datapoints[0]\n",
    "    indices = [gps_datapoints.find(keyword) for keyword in GPS_KEYWORDS_LIST]\n",
    "    # Latitude, Longtiude, Altitude, Satellite-in-view, timing for this set\n",
    "    gps_datapoints_list = []\n",
    "    for i, index in enumerate(indices):\n",
    "        if i == len(indices) - 1:\n",
    "            gps_datapoints_list.append(float(gps_datapoints[index + GPS_KEYWORDS_LENGTH[i]:].strip()))\n",
    "        else:\n",
    "            gps_datapoints_list.append(float(gps_datapoints[index + GPS_KEYWORDS_LENGTH[i]:indices[i+1]].strip()))\n",
    "    return gps_datapoints_list\n",
    "\n",
    "def process_gps(gps):\n",
    "    \"\"\"\n",
    "    gps = data['Split Circuit']['GPS']\n",
    "    \"\"\"\n",
    "    processed_gps_data = []\n",
    "    gps_accounter = gps['GPS Accounter']\n",
    "    gps_datapoints = gps['GPS Datapoints']\n",
    "    gps_loopSpeedArr = gps['GPS LoopSpeedArr'][0]\n",
    "    gps_uploadSpeedArr = gps['GPS UploadSpeedArr'][0]\n",
    "    \n",
    "    processed_gps_datapoints = process_gps_datapoints(gps_datapoints)\n",
    "    \n",
    "    processed_gps_data.append(gps_accounter)\n",
    "    processed_gps_data.extend(processed_gps_datapoints)\n",
    "    processed_gps_data.extend([gps_loopSpeedArr, gps_uploadSpeedArr])\n",
    "    \n",
    "    new_gps_df = pd.DataFrame([processed_gps_data],\n",
    "                             columns = ['accounter', 'latitude', 'longitude', 'altitude', 'satelliteInView', 'timingForThisSet', 'LoopSpeed', 'UploadSpeed'])\n",
    "    return new_gps_df\n",
    "\n",
    "# process MPU6050\n",
    "MPU6050_KEYWORDS = ['Ax: ', 'Ay: ', 'Az: ', 'gx: ', 'gy: ', 'gz: ', 'temp: ', 'timing for this set: ']\n",
    "MPU6050_KEYWORDS_LENGTH = [len(x) for x in MPU6050_KEYWORDS]\n",
    "\n",
    "## function to process one datapoint\n",
    "def process_one_set_of_datapoint(output_set):\n",
    "    indexes = [output_set.find(keyword) for keyword in MPU6050_KEYWORDS]\n",
    "    df_row = []\n",
    "    curr_data_index = int(output_set[:indexes[0]].strip())\n",
    "    df_row.append(curr_data_index) # append in the index of the new input\n",
    "    for i, index in enumerate(indexes):\n",
    "        if i == len(indexes) - 1:\n",
    "            x = float(output_set[index+MPU6050_KEYWORDS_LENGTH[i]:].strip())\n",
    "            df_row.append(x)\n",
    "        else:\n",
    "            x = float(output_set[index+MPU6050_KEYWORDS_LENGTH[i]: indexes[i+1]].strip())\n",
    "            df_row.append(x)\n",
    "    return df_row\n",
    "\n",
    "def process_mpu6050(mpu6050, timeDifference):\n",
    "    \"\"\"\n",
    "    mpu6050_output = split_circuit_data['MPU6050']\n",
    "    \"\"\"\n",
    "    mpu6050_df = pd.DataFrame(columns = ['accounter', 'LoopSpeedArr', 'UploadSpeedArr', 'set_index', 'Ax', 'Ay', 'Az', 'gx', 'gy', 'gz', 'temp', 'timingForThisSet', 'timeDifference'])\n",
    "    accounter = mpu6050['MPU6050 Accounter']\n",
    "    mpu6050_datapoints = mpu6050['MPU6050 Datapoints'][0]\n",
    "    mpu6050_loopSpeedArr = mpu6050['MPU6050 LoopSpeedArr'][0]\n",
    "    mpu6050_uploadSpeedArr = mpu6050['MPU6050 UploadSpeedArr'][0]\n",
    "    mpu6050_output_sets = mpu6050_datapoints.split('Set: ')[1:]\n",
    "    \n",
    "    for output in mpu6050_output_sets:\n",
    "        data = [accounter, mpu6050_loopSpeedArr,mpu6050_uploadSpeedArr]\n",
    "        datapoint = process_one_set_of_datapoint(output)\n",
    "        data.extend(datapoint)\n",
    "        data.append(timeDifference)\n",
    "        new_df = pd.DataFrame([data], \n",
    "                              columns = ['accounter', 'LoopSpeedArr', 'UploadSpeedArr', 'set_index', 'Ax', 'Ay', 'Az', 'gx', 'gy', 'gz', 'temp', 'timingForThisSet', 'timeDifference'])\n",
    "        mpu6050_df = pd.concat([mpu6050_df, new_df], ignore_index = True)\n",
    "    return mpu6050_df\n",
    "\n",
    "# overall function to read split circuit\n",
    "def process_split_ciruit_data(split_circuit_data):\n",
    "    \"\"\"\n",
    "    split_circuit_data = data['Split Circuit']\n",
    "    \"\"\"\n",
    "    gps_df = pd.DataFrame(columns = ['accounter', 'latitude', 'longitude', 'altitude', 'satelliteInView', 'timingForThisSet', 'LoopSpeed', 'UploadSpeed'])\n",
    "    mpu6050_df = pd.DataFrame(columns = ['accounter', 'LoopSpeedArr', 'UploadSpeedArr', 'set_index', 'Ax', 'Ay', 'Az', 'gx', 'gy', 'gz', 'temp', 'timingForThisSet', 'timeDifference'])\n",
    "\n",
    "    keys = split_circuit_data.keys()\n",
    "    for key in keys:\n",
    "        if key == 'GPS':\n",
    "            gps_data = split_circuit_data['GPS']\n",
    "            processed_gps_data = process_gps(gps_data)\n",
    "            gps_df = pd.concat([gps_df, processed_gps_data])\n",
    "            print('Extracted GPS Data')\n",
    "            \n",
    "        elif key == 'GPS Button':\n",
    "            print(\"GPS Button:\", split_circuit_data['GPS Button'])\n",
    "            \n",
    "        elif key == 'MPU6050':\n",
    "            mpu6050_output = split_circuit_data['MPU6050']\n",
    "            processed_mpu6050_output = process_mpu6050(mpu6050_output, None)\n",
    "            mpu6050_df = pd.concat([mpu6050_df, processed_mpu6050_output])\n",
    "            print('Extracted MPU6050 Data')\n",
    "    return gps_df, mpu6050_df\n",
    "\n",
    "# MAIN FUNCTION to read data from Google Firebase\n",
    "def read_data():\n",
    "    data = USERS_DATA.get()\n",
    "    split_circuit_data = data['Split Circuit']\n",
    "    gps_df, mpu6050_df = process_split_ciruit_data(split_circuit_data)\n",
    "    return gps_df, mpu6050_df\n",
    "\n",
    "def predict(wave_data, t1=8.6396, t2=0.5):\n",
    "    \"\"\"\n",
    "    Actual:\n",
    "    This function make use of the autoencoder model to predict one wave of data - 20 datapoints.\n",
    "    The model will predict whether each of this 20 datapoints is ADL or Fall from the reconstruction error threshold, t1.\n",
    "    If the number of datapoints in a wave is more than a certain threshold, t2, we will then classify it as Fall, else ADL.\n",
    "\n",
    "    For now:\n",
    "    t1 is threshold to classify one datapoint based on the y-axis of accelerometer \n",
    "    t2 is threshold to classify a wave - 0.5 i.e. if >= 50% of the datapoints are anomalous, this wave will be classified as fall\n",
    "    \"\"\"\n",
    "    return np.sum(np.abs(wave_data.Ay) > t1) >= t2 * wave_data.shape[0]\n",
    "\n",
    "def write_to_firebase(prediction, prediction_path=FIREBASE_PREDICTION_PATH):\n",
    "    \"\"\" Write results to firebase \"\"\"\n",
    "    if prediction.lower() == \"fall detected\":\n",
    "        prediction_path.update({\"0\":\"Fall Detected\"})\n",
    "    elif prediction.lower() == \"normal\":\n",
    "        prediction_path.update({\"0\":\"Normal\"})\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     while True:\n",
    "#         gps_df, mpu6050_df = read_data()\n",
    "#         print(\"GPS and MPU6050 Dataframe Shape:\", gps_df.shape, mpu6050_df.shape)\n",
    "#         # prediction = predict(wave_data=mpu6050_df.values)\n",
    "#         prediction = \"Fall detected\"\n",
    "#         print(\"Prediction:\", prediction.title())\n",
    "#         # write_to_firebase(prediction)\n",
    "#         print(\"Updated Firebase!\")\n",
    "#         print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d43871c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted GPS Data\n",
      "GPS Button: ON\n",
      "Extracted MPU6050 Data\n",
      "Extracted GPS Data\n",
      "GPS Button: ON\n",
      "Extracted MPU6050 Data\n"
     ]
    }
   ],
   "source": [
    "gps_df, mpu6050_df = read_data()\n",
    "test_data = read_data()[1][[\"Ax\", \"Ay\", \"Az\", \"gx\", \"gy\", \"gz\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0c38d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7fc51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8123b7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af43a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b26b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2daca4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
