{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c08ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import seaborn as sn\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from sklearn.preprocessing import minmax_scale, OneHotEncoder\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0919b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = \"C:/Users/ernest.liu/Documents/ZZZ Misc/UMAFall/UMAFall_Dataset Formatted/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c715725f",
   "metadata": {},
   "source": [
    "## Autoencoder approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ad4bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(home_dir)\n",
    "all_files = os.listdir()\n",
    "adl_files = []\n",
    "fall_files = []\n",
    "for file in all_files:\n",
    "    if \"adl\" in file.lower():\n",
    "        adl_files.append(file)\n",
    "    else:\n",
    "        fall_files.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feed08b2",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc55da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis, y_axis, z_axis = [], [], []\n",
    "for file in adl_files:\n",
    "    data = pd.read_csv(file)\n",
    "    sensor0 = data[(data[\" Sensor Type\"] == 0) & (data[\" Sensor ID\"] == 0)].iloc[:, range(6)]\n",
    "    sensor0.iloc[:,2] = sensor0.iloc[:,2].astype(np.float32)\n",
    "    sensor0.iloc[:,3] = sensor0.iloc[:,3].astype(np.float32)\n",
    "    sensor0.iloc[:,4] = sensor0.iloc[:,4].astype(np.float32)\n",
    "    sensor0 = sensor0.groupby(\"% TimeStamp\", as_index = False).mean()\n",
    "    x = sensor0[' X-Axis']\n",
    "    y = sensor0[' Y-Axis']\n",
    "    z = sensor0[' Z-Axis']\n",
    "    x_axis.append(x)\n",
    "    y_axis.append(y)\n",
    "    z_axis.append(z)\n",
    "    print(f\"{file} completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df67b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis_fall, y_axis_fall, z_axis_fall = [], [], []\n",
    "for file in fall_files:\n",
    "    data = pd.read_csv(file)\n",
    "    sensor0 = data[(data[\" Sensor Type\"] == 0) & (data[\" Sensor ID\"] == 0)].iloc[:, range(6)]\n",
    "    sensor0.iloc[:,2] = sensor0.iloc[:,2].astype(np.float32)\n",
    "    sensor0.iloc[:,3] = sensor0.iloc[:,3].astype(np.float32)\n",
    "    sensor0.iloc[:,4] = sensor0.iloc[:,4].astype(np.float32)\n",
    "    sensor0 = sensor0.groupby(\"% TimeStamp\", as_index = False).mean()\n",
    "    x = sensor0[' X-Axis']\n",
    "    y = sensor0[' Y-Axis']\n",
    "    z = sensor0[' Z-Axis']\n",
    "    x_axis_fall.append(x)\n",
    "    y_axis_fall.append(y)\n",
    "    z_axis_fall.append(z)\n",
    "    print(f\"{file} completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da348397",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min_count = 4000\n",
    "for d in x_axis:\n",
    "    if x_min_count > len(d):\n",
    "        x_min_count = len(d)\n",
    "for d in x_axis_fall:\n",
    "    if x_min_count > len(d):\n",
    "        x_min_count = len(d)\n",
    "for i, arr in enumerate(x_axis):\n",
    "    x_axis[i] = arr[:x_min_count]\n",
    "for i, arr in enumerate(x_axis_fall):\n",
    "    x_axis_fall[i] = arr[:x_min_count]\n",
    "x_axis = np.array(x_axis)\n",
    "x_axis_fall = np.array(x_axis_fall)\n",
    "        \n",
    "y_min_count = 4000\n",
    "for d in y_axis:\n",
    "    if y_min_count > len(d):\n",
    "        y_min_count = len(d)\n",
    "for d in y_axis_fall:\n",
    "    if y_min_count > len(d):\n",
    "        y_min_count = len(d)\n",
    "for i, arr in enumerate(y_axis):\n",
    "    y_axis[i] = arr[:y_min_count]\n",
    "for i, arr in enumerate(y_axis_fall):\n",
    "    y_axis_fall[i] = arr[:y_min_count]\n",
    "y_axis = np.array(y_axis)\n",
    "y_axis_fall = np.array(y_axis_fall)\n",
    "        \n",
    "z_min_count = 4000\n",
    "for d in z_axis:\n",
    "    if z_min_count > len(d):\n",
    "        z_min_count = len(d)\n",
    "for d in z_axis_fall:\n",
    "    if z_min_count > len(d):\n",
    "        z_min_count = len(d)\n",
    "for i, arr in enumerate(z_axis):\n",
    "    z_axis[i] = arr[:z_min_count]\n",
    "for i, arr in enumerate(z_axis_fall):\n",
    "    z_axis_fall[i] = arr[:z_min_count]\n",
    "z_axis = np.array(z_axis)\n",
    "z_axis_fall = np.array(z_axis_fall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c42850",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a3f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad698fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c791240c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f4923d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2794e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e826f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8501e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data_clean = np.delete(x_axis, [304,305,306], axis = 0)\n",
    "x_train_data_clean = preprocessing.normalize(x_train_data_clean)\n",
    "x_axis_fall_clean = preprocessing.normalize(x_axis_fall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccfb318",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis_clean = preprocessing.normalize(y_axis)\n",
    "y_axis_fall_clean = preprocessing.normalize(y_axis_fall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d098e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_jumps = sorted(abs((y_axis_clean[:,:-1] - y_axis_clean[:,1:]).flatten()), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e287ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(np.where(abs(y_axis_clean[:,:-1] - y_axis_clean[:,1:]) >= 0.2)[0]))\n",
    "print(\"Therefore, we remove rows 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 from our dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e468415",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis_clean = np.delete(y_axis_clean, range(299,316), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae40cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(abs(y_axis_clean[:,:-1] - y_axis_clean[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66fac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 335\n",
    "plt.grid()\n",
    "plt.plot(np.arange(len(y_axis_clean[index])), y_axis_clean[index])\n",
    "plt.title(\"ADL y-axis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d1d396",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_axis_clean = preprocessing.normalize(z_axis)\n",
    "z_axis_fall_clean = preprocessing.normalize(z_axis_fall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afda903",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_jumps = sorted(abs((z_axis_clean[:,:-1] - z_axis_clean[:,1:]).flatten()), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff86f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove_z = np.unique(np.where(abs(z_axis_clean[:,:-1] - z_axis_clean[:,1:]) >= 0.2)[0])\n",
    "print(to_remove_z)\n",
    "print(f\"Therefore, we remove rows {to_remove_z} from our dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b504343",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_axis_clean = np.delete(z_axis_clean, to_remove_z, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef78df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2\n",
    "plt.grid()\n",
    "plt.plot(np.arange(len(z_axis_clean[index])), z_axis_clean[index])\n",
    "plt.title(\"ADL z-axis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b39499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.8\n",
    "\n",
    "x_train_data = x_train_data_clean[:round(len(x_train_data_clean)*ratio)]\n",
    "x_test_data = x_train_data_clean[round(len(x_train_data_clean)*ratio):]\n",
    "\n",
    "\n",
    "y_train_data = y_axis_clean[:round(len(y_axis_clean)*ratio)]\n",
    "y_test_data = y_axis_clean[round(len(y_axis_clean)*ratio):]\n",
    "\n",
    "# Not done\n",
    "z_train_data = z_axis_clean[:round(len(z_axis_clean)*ratio)]\n",
    "z_test_data = z_axis_clean[round(len(z_axis_clean)*ratio):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935d5c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 306\n",
    "plt.grid()\n",
    "plt.plot(np.arange(len(x_train_data[index])), x_train_data[index])\n",
    "plt.title(\"ADL x-axis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362b41a5",
   "metadata": {},
   "source": [
    "### Building Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce4cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Dense(500, activation = 'relu')\n",
    "            #layers.Dense(1000, activation = 'relu'),\n",
    "            #layers.Dense(900, activation = 'relu'),\n",
    "            #layers.Dense(800, activation = 'relu')\n",
    "        ])\n",
    "        \n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            #layers.Dense(900, activation = 'relu'),\n",
    "            #layers.Dense(1000, activation = 'relu'),\n",
    "            layers.Dense(1173, activation = 'sigmoid')\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "autoencoder_x = Autoencoder()\n",
    "autoencoder_y = Autoencoder()\n",
    "autoencoder_z = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2995af",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_x.compile(optimizer = 'adam', loss = 'mae')\n",
    "autoencoder_y.compile(optimizer = 'adam', loss = 'mae')\n",
    "autoencoder_z.compile(optimizer = 'adam', loss = 'mae')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e2a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_x = autoencoder_x.fit(x_train_data, x_train_data,\n",
    "                         epochs = 100000,\n",
    "                         batch_size = 32,\n",
    "                         validation_data = (x_test_data, x_test_data),\n",
    "                         shuffle = True, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_y = autoencoder_y.fit(y_train_data, y_train_data,\n",
    "                         epochs = 100000,\n",
    "                         batch_size = 32,\n",
    "                         validation_data = (y_test_data, y_test_data),\n",
    "                         shuffle = True, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfef3f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_z = autoencoder_z.fit(z_train_data, z_train_data,\n",
    "                         epochs = 100000,\n",
    "                         batch_size = 32,\n",
    "                         validation_data = (z_test_data, z_test_data),\n",
    "                         shuffle = True, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18778f23",
   "metadata": {},
   "source": [
    "### Inspecting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d9f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, predictions):\n",
    "    y_true, predictions = np.array(y_true), np.array(predictions)\n",
    "    return np.mean(np.abs(y_true - predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d18609",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_x = autoencoder_x.predict(x_train_data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08042953",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096333e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068d1392",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(index)\n",
    "print(f\"MAE: {mae(predicted_x[index], x_train_data_clean[index])}\")\n",
    "plt.plot(predicted_x[index], 'r')\n",
    "plt.plot(x_train_data_clean[index], 'b')\n",
    "\n",
    "plt.fill_between(np.arange(1173), predicted_x[index], x_train_data_clean[index], color = 'lightcoral')\n",
    "plt.legend(labels = ['Reconstruction', 'Input', 'Error'])\n",
    "plt.show()\n",
    "index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7bddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = autoencoder_y.predict(y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cefeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a289e31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(index)\n",
    "print(f\"MAE: {mae(predicted_y[index], y_train_data[index])}\")\n",
    "plt.plot(predicted_y[index], 'r')\n",
    "plt.plot(y_train_data[index], 'b')\n",
    "\n",
    "plt.fill_between(np.arange(1173), predicted_y[index], y_train_data[index], color = 'lightcoral')\n",
    "plt.legend(labels = ['Reconstruction', 'Input', 'Error'])\n",
    "plt.show()\n",
    "index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07346e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_scores = [mae(predicted_y[i], y_train_data[i]) for i in range(y_train_data.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d01baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(mae_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5434bbf6",
   "metadata": {},
   "source": [
    "### Determining Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac28a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "adl_loss_x = tf.keras.losses.mae(predicted_x, x_train_data_clean)\n",
    "plt.hist(adl_loss_x[None,:], bins = 50)\n",
    "plt.xlabel(\"ADL loss\")\n",
    "plt.ylabel(\"No of examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb8cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_fall = autoencoder_x.predict(x_axis_fall_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c0bbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_loss_x = tf.keras.losses.mae(predicted_fall, x_axis_fall_clean)\n",
    "plt.hist(fall_loss_x[None,:], bins = 50)\n",
    "plt.xlabel(\"Fall loss\")\n",
    "plt.ylabel(\"No of examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6667a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.mean(fall_loss_x) - np.std(fall_loss_x)\n",
    "print(f\"threshold: {threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf64a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_evaluation(adl_loss, fall_loss, threshold):\n",
    "    train_total = len(adl_loss)\n",
    "    test_total = len(fall_loss)\n",
    "\n",
    "    tp = np.count_nonzero(fall_loss > threshold) # right side of fall\n",
    "    fp = np.count_nonzero(adl_loss > threshold) # right side of adl\n",
    "    fn = np.count_nonzero(fall_loss <= threshold) # left side of fall\n",
    "    tn = np.count_nonzero(adl_loss <= threshold) # left side of adl\n",
    "    print(f'True Positives: {tp}')\n",
    "    print(f'False Positives: {fp}')\n",
    "    print(f'False Negatives: {fn}')\n",
    "    print(f'True Negatives: {tn}')\n",
    "    print()\n",
    "\n",
    "    acc = accuracy(adl_loss, fall_loss, threshold)\n",
    "    prec = precision(adl_loss, fall_loss, threshold)\n",
    "    rec = recall(adl_loss, fall_loss, threshold)\n",
    "    f1_score = f1(adl_loss, fall_loss, threshold)\n",
    "    f1_weighted = weighted_f1(adl_loss, fall_loss, threshold) # prioritising precision\n",
    "    print('------------------')\n",
    "    print('Evalutaion Metrics')\n",
    "    print('------------------')\n",
    "    print(f'Accuracy: {round(acc,3)}')\n",
    "    print(f'Precision: {round(prec,3)}')\n",
    "    print(f'Recall: {round(rec,3)}')\n",
    "    print(f'F1 Score: {round(f1_score,3)}')\n",
    "    print(f'Weighted F1 Score: {round(f1_weighted,3)}')\n",
    "\n",
    "\n",
    "def accuracy(adl_loss, fall_loss, threshold):\n",
    "    tp = np.count_nonzero(fall_loss > threshold) # right side of fall\n",
    "    fp = np.count_nonzero(adl_loss > threshold) # right side of adl\n",
    "    fn = np.count_nonzero(fall_loss <= threshold) # left side of fall\n",
    "    tn = np.count_nonzero(adl_loss <= threshold) # left side of adl\n",
    "    return (tp+tn)/(tp+fp+fn+tn)\n",
    "\n",
    "def precision(adl_loss, fall_loss, threshold):\n",
    "    tp = np.count_nonzero(fall_loss > threshold) # right side of fall\n",
    "    fp = np.count_nonzero(adl_loss > threshold) # right side of adl\n",
    "    fn = np.count_nonzero(fall_loss <= threshold) # left side of fall\n",
    "    tn = np.count_nonzero(adl_loss <= threshold) # left side of adl\n",
    "    try:\n",
    "        return tp/(tp+fp)\n",
    "    except: return 0\n",
    "\n",
    "def recall(adl_loss, fall_loss, threshold):\n",
    "    tp = np.count_nonzero(fall_loss > threshold) # right side of fall\n",
    "    fp = np.count_nonzero(adl_loss > threshold) # right side of adl\n",
    "    fn = np.count_nonzero(fall_loss <= threshold) # left side of fall\n",
    "    tn = np.count_nonzero(adl_loss <= threshold) # left side of adl\n",
    "    try:\n",
    "        return tp/(tp+fn)\n",
    "    except: return 0\n",
    "\n",
    "def f1(adl_loss, fall_loss, threshold):\n",
    "    tp = np.count_nonzero(fall_loss > threshold) # right side of fall\n",
    "    fp = np.count_nonzero(adl_loss > threshold) # right side of adl\n",
    "    fn = np.count_nonzero(fall_loss <= threshold) # left side of fall\n",
    "    tn = np.count_nonzero(adl_loss <= threshold) # left side of adl\n",
    "    prec = precision(adl_loss, fall_loss, threshold)\n",
    "    rec = recall(adl_loss, fall_loss, threshold)\n",
    "    try:\n",
    "        return 2*((prec*rec)/(prec+rec))\n",
    "    except: return 0\n",
    "\n",
    "def weighted_f1(adl_loss, fall_loss, threshold, beta=0.7):\n",
    "\n",
    "    tp = np.count_nonzero(fall_loss > threshold) # right side of fall\n",
    "    fp = np.count_nonzero(adl_loss > threshold) # right side of adl\n",
    "    fn = np.count_nonzero(fall_loss <= threshold) # left side of fall\n",
    "    tn = np.count_nonzero(adl_loss <= threshold) # left side of adl\n",
    "\n",
    "    prec = precision(adl_loss, fall_loss, threshold)\n",
    "    rec = recall(adl_loss, fall_loss, threshold)\n",
    "    try:\n",
    "        return (1+beta**2) * ((prec*rec)/(beta**2*prec+rec))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "    \n",
    "compute_evaluation(adl_loss_x, fall_loss_x, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f847441",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_threshold = min(np.min(adl_loss_x), np.min(fall_loss_x))\n",
    "max_threshold = max(np.max(adl_loss_x), np.max(fall_loss_x))\n",
    "threshold_list = np.linspace(min_threshold, max_threshold, num = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b01f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_f1_score_list = [weighted_f1(adl_loss_x, fall_loss_x, threshold, beta = 0.5) for threshold in threshold_list]\n",
    "precision_list = [precision(adl_loss_x, fall_loss_x, threshold) for threshold in threshold_list]\n",
    "recall_list = [recall(adl_loss_x, fall_loss_x, threshold) for threshold in threshold_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c1743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(threshold_list, weighted_f1_score_list)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"weighted f1 score list\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb5b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.argmax(weighted_f1_score_list)\n",
    "print(f\"Highest Weighted F1 Score: {weighted_f1_score_list[index]}\")\n",
    "print(f\"Best Threshold: {threshold_list[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b9b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(adl_loss_x, fall_loss_x, threshold_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087fe22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision(adl_loss_x, fall_loss_x, threshold_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770a7f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall(adl_loss_x, fall_loss_x, threshold_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea42674",
   "metadata": {},
   "outputs": [],
   "source": [
    "adl_loss_y = tf.keras.losses.mae(predicted_y, y_train_data)\n",
    "plt.hist(adl_loss_y[None,:], bins = 50)\n",
    "plt.xlabel(\"ADL loss\")\n",
    "plt.ylabel(\"No of examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_fall = autoencoder_y.predict(y_axis_fall_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba58117",
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_loss_y = tf.keras.losses.mae(predicted_fall, y_axis_fall_clean)\n",
    "plt.hist(fall_loss_y[None,:], bins = 50)\n",
    "plt.xlabel(\"Fall loss\")\n",
    "plt.ylabel(\"No of examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735859b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.mean(fall_loss_y) - np.std(fall_loss_y)\n",
    "print(f\"threshold: {threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96228bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_threshold = min(np.min(adl_loss_y), np.min(fall_loss_y))\n",
    "max_threshold = max(np.max(adl_loss_y), np.max(fall_loss_y))\n",
    "threshold_list = np.linspace(min_threshold, max_threshold, num = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb7e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_f1_score_list = [weighted_f1(adl_loss_y, fall_loss_y, threshold, beta = 0.5) for threshold in threshold_list]\n",
    "precision_list = [precision(adl_loss_y, fall_loss_y, threshold) for threshold in threshold_list]\n",
    "recall_list = [recall(adl_loss_y, fall_loss_y, threshold) for threshold in threshold_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea1e5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(threshold_list, weighted_f1_score_list)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"weighted f1 score list\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ba4251",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.argmax(weighted_f1_score_list)\n",
    "print(f\"Highest Weighted F1 Score: {weighted_f1_score_list[index]}\")\n",
    "print(f\"Best Threshold: {threshold_list[index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bec420",
   "metadata": {},
   "source": [
    "# ANN Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40262f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adl = x_train_data_clean\n",
    "x_fall = x_axis_fall_clean\n",
    "\n",
    "y_adl = y_axis_clean\n",
    "y_fall = y_axis_fall_clean\n",
    "\n",
    "z_adl = z_axis_clean\n",
    "z_fall = z_axis_fall_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ba3f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.concatenate([x_adl, x_fall])\n",
    "y_data = np.concatenate([y_adl, y_fall])\n",
    "z_data = np.concatenate([z_adl, z_fall])\n",
    "\n",
    "print(f\"\"\"\n",
    "x_data: {x_data.shape[0]}\n",
    "y_data: {y_data.shape[0]}\n",
    "z_data: {z_data.shape[0]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0dc606",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = np.concatenate([np.zeros((x_adl.shape[0], 1)), np.ones((x_fall.shape[0], 1))], axis = 0)\n",
    "y_labels = np.concatenate([np.zeros((y_adl.shape[0], 1)), np.ones((y_fall.shape[0], 1))], axis = 0)\n",
    "z_labels = np.concatenate([np.zeros((z_adl.shape[0], 1)), np.ones((z_fall.shape[0], 1))], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percent = 0.2\n",
    "np.random.seed(100)\n",
    "x_test_ind = sorted(np.random.choice(range(x_data.shape[0]), replace = False, size = round(x_data.shape[0] * test_percent)))\n",
    "y_test_ind = sorted(np.random.choice(range(y_data.shape[0]), replace = False, size = round(y_data.shape[0] * test_percent)))\n",
    "z_test_ind = sorted(np.random.choice(range(z_data.shape[0]), replace = False, size = round(z_data.shape[0] * test_percent)))\n",
    "x_train_ind = np.delete(np.arange(0, x_data.shape[0]), x_test_ind)\n",
    "y_train_ind = np.delete(np.arange(0, y_data.shape[0]), y_test_ind)\n",
    "z_train_ind = np.delete(np.arange(0, z_data.shape[0]), z_test_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1dc635",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data = x_data[x_train_ind, :]\n",
    "y_train_data = y_data[y_train_ind, :]\n",
    "z_train_data = z_data[z_train_ind, :]\n",
    "\n",
    "x_train_labels = x_labels[x_train_ind, :]\n",
    "y_train_labels = y_labels[y_train_ind, :]\n",
    "z_train_labels = z_labels[z_train_ind, :]\n",
    "\n",
    "x_test_data = x_data[x_test_ind, :]\n",
    "y_test_data = y_data[y_test_ind, :]\n",
    "z_test_data = z_data[z_test_ind, :]\n",
    "\n",
    "x_test_labels = x_labels[x_test_ind, :]\n",
    "y_test_labels = y_labels[y_test_ind, :]\n",
    "z_test_labels = z_labels[z_test_ind, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(x_train_labels)\n",
    "\n",
    "x_train_labels = enc.transform(x_train_labels).toarray()\n",
    "x_test_labels = enc.transform(x_test_labels).toarray()\n",
    "\n",
    "y_train_labels = enc.transform(y_train_labels).toarray()\n",
    "y_test_labels = enc.transform(y_test_labels).toarray()\n",
    "\n",
    "z_train_labels = enc.transform(z_train_labels).toarray()\n",
    "z_test_labels = enc.transform(z_test_labels).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c93d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8233c2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_x = tf.keras.Sequential([\n",
    "    layers.Dense(400, activation = 'relu'),\n",
    "    layers.Dense(300, activation = 'relu'),\n",
    "    layers.Dense(150, activation = 'relu'),\n",
    "    layers.Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model_y = tf.keras.Sequential([\n",
    "    layers.Dense(400, activation = 'relu'),\n",
    "    layers.Dense(300, activation = 'relu'),\n",
    "    layers.Dense(150, activation = 'relu'),\n",
    "    layers.Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model_z = tf.keras.Sequential([\n",
    "    layers.Dense(400, activation = 'relu'),\n",
    "    layers.Dense(300, activation = 'relu'),\n",
    "    layers.Dense(150, activation = 'relu'),\n",
    "    layers.Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model_x.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model_y.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model_z.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9394aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_x = model_x.fit(x_train_data, x_train_labels,\n",
    "                    validation_data = (x_test_data, x_test_labels),\n",
    "                    epochs = 100,\n",
    "                    callbacks = [early_stopping],\n",
    "                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6ed794",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_y = model_y.fit(y_train_data, y_train_labels,\n",
    "                    validation_data = (y_test_data, y_test_labels),\n",
    "                    epochs = 100,\n",
    "                    callbacks = [early_stopping],\n",
    "                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1c58a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_z = model_z.fit(z_train_data, z_train_labels,\n",
    "                    validation_data = (z_test_data, z_test_labels),\n",
    "                    epochs = 100,\n",
    "                    callbacks = [early_stopping],\n",
    "                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77fa7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_x = model_x.predict(x_test_data)\n",
    "predicted_x = [np.argmax(i) for i in predicted_x]\n",
    "actual_x = [np.argmax(i) for i in x_test_labels]\n",
    "\n",
    "cf_matrix = confusion_matrix(predicted_x, actual_x)\n",
    "\n",
    "ax = sn.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['ADL','Fall'])\n",
    "ax.yaxis.set_ticklabels(['ADL','Fall'])\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a3a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = model_y.predict(y_test_data)\n",
    "predicted_y = [np.argmax(i) for i in predicted_y]\n",
    "actual_y = [np.argmax(i) for i in y_test_labels]\n",
    "\n",
    "cf_matrix = confusion_matrix(predicted_y, actual_y)\n",
    "\n",
    "ax = sn.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['ADL','Fall'])\n",
    "ax.yaxis.set_ticklabels(['ADL','Fall'])\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822b373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_z = model_z.predict(z_test_data)\n",
    "predicted_z = [np.argmax(i) for i in predicted_z]\n",
    "actual_z = [np.argmax(i) for i in z_test_labels]\n",
    "\n",
    "cf_matrix = confusion_matrix(predicted_z, actual_z)\n",
    "\n",
    "ax = sn.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['ADL','Fall'])\n",
    "ax.yaxis.set_ticklabels(['ADL','Fall'])\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd453d87",
   "metadata": {},
   "source": [
    "# 1D CNN Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567b0e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_x = tf.keras.Sequential([\n",
    "    Conv1D(filters = 64, kernel_size = 3, activation = 'relu'),\n",
    "    Conv1D(filters = 64, kernel_size = 3, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPooling1D(pool_size = 2),\n",
    "    Flatten(),\n",
    "    layers.Dense(400, activation = 'relu'),\n",
    "    layers.Dense(300, activation = 'relu'),\n",
    "    layers.Dense(150, activation = 'relu'),\n",
    "    layers.Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model_x.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fd4369",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data_reshaped = x_train_data[..., None]\n",
    "x_test_data_reshaped = x_test_data[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41775b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_x = cnn_model_x.fit(x_train_data_reshaped, x_train_labels,\n",
    "                    validation_data = (x_test_data_reshaped, x_test_labels),\n",
    "                    epochs = 100,\n",
    "                    callbacks = [early_stopping],\n",
    "                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da3f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_x = cnn_model_x.predict(x_test_data)\n",
    "predicted_x = [np.argmax(i) for i in predicted_x]\n",
    "actual_x = [np.argmax(i) for i in x_test_labels]\n",
    "\n",
    "cf_matrix = confusion_matrix(predicted_x, actual_x)\n",
    "\n",
    "ax = sn.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['ADL','Fall'])\n",
    "ax.yaxis.set_ticklabels(['ADL','Fall'])\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f93b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_y = tf.keras.Sequential([\n",
    "    Conv1D(filters = 64, kernel_size = 3, activation = 'relu'),\n",
    "    Conv1D(filters = 64, kernel_size = 3, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPooling1D(pool_size = 2),\n",
    "    Flatten(),\n",
    "    layers.Dense(400, activation = 'relu'),\n",
    "    layers.Dense(300, activation = 'relu'),\n",
    "    layers.Dense(150, activation = 'relu'),\n",
    "    layers.Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model_y.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0864305",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_data_reshaped = y_train_data[..., None]\n",
    "y_test_data_reshaped = y_test_data[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ba78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_y = cnn_model_y.fit(y_train_data_reshaped, y_train_labels,\n",
    "                    validation_data = (y_test_data_reshaped, y_test_labels),\n",
    "                    epochs = 100,\n",
    "                    callbacks = [early_stopping],\n",
    "                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e0a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = cnn_model_y.predict(y_test_data)\n",
    "predicted_y = [np.argmax(i) for i in predicted_y]\n",
    "actual_y = [np.argmax(i) for i in y_test_labels]\n",
    "\n",
    "cf_matrix = confusion_matrix(predicted_y, actual_y)\n",
    "\n",
    "ax = sn.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['ADL','Fall'])\n",
    "ax.yaxis.set_ticklabels(['ADL','Fall'])\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8410f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_z = tf.keras.Sequential([\n",
    "    Conv1D(filters = 64, kernel_size = 3, activation = 'relu'),\n",
    "    Conv1D(filters = 64, kernel_size = 3, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPooling1D(pool_size = 2),\n",
    "    Flatten(),\n",
    "    layers.Dense(400, activation = 'relu'),\n",
    "    layers.Dense(300, activation = 'relu'),\n",
    "    layers.Dense(150, activation = 'relu'),\n",
    "    layers.Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model_z.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eb2e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train_data_reshaped = z_train_data[..., None]\n",
    "z_test_data_reshaped = z_test_data[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d4b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_z = cnn_model_z.fit(z_train_data_reshaped, z_train_labels,\n",
    "                    validation_data = (z_test_data_reshaped, z_test_labels),\n",
    "                    epochs = 100,\n",
    "                    callbacks = [early_stopping],\n",
    "                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d467fc4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_z = cnn_model_z.predict(z_test_data)\n",
    "predicted_z = [np.argmax(i) for i in predicted_z]\n",
    "actual_z = [np.argmax(i) for i in z_test_labels]\n",
    "\n",
    "cf_matrix = confusion_matrix(predicted_z, actual_z)\n",
    "\n",
    "ax = sn.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['ADL','Fall'])\n",
    "ax.yaxis.set_ticklabels(['ADL','Fall'])\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97b7676",
   "metadata": {},
   "source": [
    "### 1D-CNN with Maximum Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac91443",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = sorted(np.unique(np.concatenate(([304,305,306],\n",
    "[299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315],\n",
    "[3,  54,  78, 141, 142, 152, 159, 170, 171, 172, 176, 207, 208, 209, 266, 267, 268, 297,\n",
    " 299, 300, 301, 303, 304, 305, 306, 307, 309, 310, 313, 314, 315, 376, 399, 413, 428, 439,\n",
    " 442, 514,]))))\n",
    "to_keep = np.delete(np.arange(0,len(x_axis)), to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc84be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adl = x_axis[to_keep]\n",
    "y_adl = y_axis[to_keep]\n",
    "z_adl = z_axis[to_keep]\n",
    "x_data = np.concatenate([x_adl, x_fall])\n",
    "x_data = np.concatenate([x_adl, x_fall])\n",
    "x_data = np.concatenate([x_adl, x_fall])\n",
    "\n",
    "x_labels = np.concatenate([np.zeros((len(x_adl),)), np.ones((len(x_fall),))])\n",
    "y_labels = np.concatenate([np.zeros((len(x_adl),)), np.ones((len(x_fall),))])\n",
    "z_labels = np.concatenate([np.zeros((len(x_adl),)), np.ones((len(x_fall),))])\n",
    "\n",
    "x_labels = x_labels.reshape(-1, 1)\n",
    "y_labels = y_labels.reshape(-1, 1)\n",
    "z_labels = z_labels.reshape(-1, 1)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(x_labels)\n",
    "\n",
    "x_labels = enc.transform(x_labels).toarray()\n",
    "y_labels = enc.transform(y_labels).toarray()\n",
    "z_labels = enc.transform(z_labels).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d53d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percent = 0.2\n",
    "np.random.seed(100)\n",
    "test_ind =  sorted(np.random.choice(range(x_data.shape[0]), replace = False, size = round(x_data.shape[0] * test_percent)))\n",
    "train_ind = np.delete(np.arange(0, x_data.shape[0]), test_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7926bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data = x_data[train_ind, :]\n",
    "y_train_data = y_data[train_ind, :]\n",
    "z_train_data = z_data[train_ind, :]\n",
    "\n",
    "x_train_labels = x_labels[train_ind, :]\n",
    "y_train_labels = y_labels[train_ind, :]\n",
    "z_train_labels = z_labels[train_ind, :]\n",
    "\n",
    "x_test_data = x_data[test_ind, :]\n",
    "y_test_data = y_data[test_ind, :]\n",
    "z_test_data = z_data[test_ind, :]\n",
    "\n",
    "x_test_labels = x_labels[test_ind, :]\n",
    "y_test_labels = y_labels[test_ind, :]\n",
    "z_test_labels = z_labels[test_ind, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fe7181",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_x = tf.keras.Sequential([\n",
    "    Conv1D(filters = 64, kernel_size = 3, activation = 'relu'),\n",
    "    Conv1D(filters = 64, kernel_size = 3, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPooling1D(pool_size = 2),\n",
    "    Flatten(),\n",
    "    layers.Dense(400, activation = 'relu'),\n",
    "    layers.Dense(300, activation = 'relu'),\n",
    "    layers.Dense(150, activation = 'relu'),\n",
    "    layers.Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model_x.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b49319",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data_reshaped = x_train_data[..., None]\n",
    "x_test_data_reshaped = x_test_data[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_x = cnn_model_x.fit(x_train_data_reshaped, x_train_labels,\n",
    "                    validation_data = (x_test_data_reshaped, x_test_labels),\n",
    "                    epochs = 100,\n",
    "                    callbacks = [early_stopping],\n",
    "                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ce0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_x = cnn_model_x.predict(x_test_data)\n",
    "predicted_x = [np.argmax(i) for i in predicted_x]\n",
    "actual_x = [np.argmax(i) for i in x_test_labels]\n",
    "\n",
    "cf_matrix = confusion_matrix(predicted_x, actual_x)\n",
    "\n",
    "ax = sn.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['ADL','Fall'])\n",
    "ax.yaxis.set_ticklabels(['ADL','Fall'])\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6255a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_y = tf.keras.Sequential([\n",
    "    Conv1D(filters = 64, kernel_size = 3, activation = 'relu'),\n",
    "    Conv1D(filters = 64, kernel_size = 3, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPooling1D(pool_size = 2),\n",
    "    Flatten(),\n",
    "    layers.Dense(400, activation = 'relu'),\n",
    "    layers.Dense(300, activation = 'relu'),\n",
    "    layers.Dense(150, activation = 'relu'),\n",
    "    layers.Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model_y.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c880bde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_data_reshaped = y_train_data[..., None]\n",
    "y_test_data_reshaped = y_test_data[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ef265",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_y = cnn_model_y.fit(y_train_data_reshaped, y_train_labels,\n",
    "                    validation_data = (y_test_data_reshaped, y_test_labels),\n",
    "                    epochs = 100,\n",
    "                    callbacks = [early_stopping],\n",
    "                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf92deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = cnn_model_y.predict(y_test_data)\n",
    "predicted_y = [np.argmax(i) for i in predicted_y]\n",
    "actual_y = [np.argmax(i) for i in y_test_labels]\n",
    "\n",
    "cf_matrix = confusion_matrix(predicted_y, actual_y)\n",
    "\n",
    "ax = sn.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['ADL','Fall'])\n",
    "ax.yaxis.set_ticklabels(['ADL','Fall'])\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2b6d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_z = tf.keras.Sequential([\n",
    "    Conv1D(filters = 64, kernel_size = 3, activation = 'relu'),\n",
    "    Conv1D(filters = 64, kernel_size = 3, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPooling1D(pool_size = 2),\n",
    "    Flatten(),\n",
    "    layers.Dense(400, activation = 'relu'),\n",
    "    layers.Dense(300, activation = 'relu'),\n",
    "    layers.Dense(150, activation = 'relu'),\n",
    "    layers.Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model_z.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8109538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train_data_reshaped = z_train_data[..., None]\n",
    "z_test_data_reshaped = z_test_data[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d601ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_z = cnn_model_z.fit(z_train_data_reshaped, z_train_labels,\n",
    "                    validation_data = (z_test_data_reshaped, z_test_labels),\n",
    "                    epochs = 100,\n",
    "                    callbacks = [early_stopping],\n",
    "                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf668ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_z = cnn_model_z.predict(z_test_data)\n",
    "predicted_z = [np.argmax(i) for i in predicted_z]\n",
    "actual_z = [np.argmax(i) for i in z_test_labels]\n",
    "\n",
    "cf_matrix = confusion_matrix(predicted_z, actual_z)\n",
    "\n",
    "ax = sn.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['ADL','Fall'])\n",
    "ax.yaxis.set_ticklabels(['ADL','Fall'])\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f36605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting maximum votes\n",
    "predicted_z = cnn_model_z.predict(z_test_data)\n",
    "predicted_z = [np.argmax(i) for i in predicted_z]\n",
    "actual_z = [np.argmax(i) for i in z_test_labels]\n",
    "\n",
    "cf_matrix = confusion_matrix(predicted_z, actual_z)\n",
    "\n",
    "ax = sn.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['ADL','Fall'])\n",
    "ax.yaxis.set_ticklabels(['ADL','Fall'])\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db808bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = (np.array(predicted_x) + np.array(predicted_y) + np.array(predicted_z)) >= 2\n",
    "actual = [np.argmax(i) for i in x_test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef53d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting maximum votes\n",
    "cf_matrix = confusion_matrix(predicted, actual)\n",
    "\n",
    "ax = sn.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n",
    "ax.set_xlabel('\\nActual Values')\n",
    "ax.set_ylabel('Predicted Values')\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['ADL','Fall'])\n",
    "ax.yaxis.set_ticklabels(['ADL','Fall'])\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73beef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == 1 and actual[i] == 0:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e07e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_model_x.save(\"cnn_model_x_axis_UMAFall\")\n",
    "# cnn_model_y.save(\"cnn_model_y_axis_UMAFall\")\n",
    "# cnn_model_z.save(\"cnn_model_z_axis_UMAFall\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe6da7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
