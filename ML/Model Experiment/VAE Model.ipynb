{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "738e729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange\n",
    "from time import time\n",
    "\n",
    "from sklearn.covariance import MinCovDet\n",
    "from scipy.stats import chi2\n",
    "\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing, linear_model\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from sklearn.preprocessing import minmax_scale, OneHotEncoder\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Input, Dense, Reshape, Concatenate, Flatten, Lambda, Reshape, Dropout\n",
    "from keras.losses import MeanSquaredError as mse\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dfc24e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fall_simulation',\n",
       " 'fall_simulation2',\n",
       " 'fall_simulation3',\n",
       " 'fall_simulation_2.csv',\n",
       " 'fall_simulation_3.csv',\n",
       " 'trial_data_1',\n",
       " 'trial_data_2',\n",
       " 'trial_data_3',\n",
       " 'trial_data_4',\n",
       " 'trial_data_4.csv',\n",
       " 'trial_data_5',\n",
       " 'trial_data_5.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASETS_PATH = \"C:/Users/ernest.liu/Documents/git/Morphine-22-23/ML/Datasets/19-01-2023/\"\n",
    "os.chdir(DATASETS_PATH)\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf4816e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trial_data_4.csv', 'trial_data_5.csv']\n",
      "['fall_simulation_2.csv', 'fall_simulation_3.csv']\n"
     ]
    }
   ],
   "source": [
    "adl_files = [file_name for file_name in os.listdir() if \".csv\" in file_name and \"trial\" in file_name]\n",
    "fall_files = [file_name for file_name in os.listdir() if \".csv\" in file_name and \"fall\" in file_name]\n",
    "\n",
    "print(adl_files)\n",
    "print(fall_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd65722",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data_4 = pd.read_csv(DATASETS_PATH+'trial_data_4.csv').iloc[:,1:]\n",
    "trial_data_5 = pd.read_csv(DATASETS_PATH+'trial_data_5.csv').iloc[:,1:]\n",
    "\n",
    "fall_simulation_2 = pd.read_csv(DATASETS_PATH+'fall_simulation_2.csv').iloc[:,1:]\n",
    "fall_simulation_3 = pd.read_csv(DATASETS_PATH+'fall_simulation_3.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "189b1c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only take in accelerometer and gyroscope data\n",
    "trial_data_4 = trial_data_4[['Ax','Ay','Az','gx','gy','gz']]\n",
    "trial_data_5 = trial_data_5[['Ax','Ay','Az','gx','gy','gz']]\n",
    "\n",
    "fall_simulation_2 = fall_simulation_2[['Ax','Ay','Az','gx','gy','gz']]\n",
    "fall_simulation_3 = fall_simulation_3[['Ax','Ay','Az','gx','gy','gz']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63007455",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([trial_data_4, trial_data_5]).reset_index(drop=True)\n",
    "test_data = pd.concat([fall_simulation_2, fall_simulation_3]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c8bf526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EDA\n",
    "plt.hist(np.abs(train_data.Ay), bins=50, alpha=0.5, density=True)\n",
    "plt.hist(np.abs(test_data.Ay), bins=50, alpha=0.5, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e37a0e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7044129",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_norm_presplit = scaler.transform(train_data)\n",
    "test_data_norm = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da93a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ratio = 0.2\n",
    "valid_indices = sorted(random.sample(list(range(train_data_norm_presplit.shape[0])), round(train_data_norm_presplit.shape[0] * valid_ratio)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4601de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = train_data.iloc[valid_indices, :].reset_index(drop = True)\n",
    "valid_data_norm = train_data_norm_presplit[valid_indices]\n",
    "train_data_norm = np.delete(train_data_norm_presplit, valid_indices, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50264422",
   "metadata": {},
   "source": [
    "## Mahalanobis Distance Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881a3204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance matrix\n",
    "# covariance = np.cov(train_data, rowvar=False)\n",
    "\n",
    "start_time = time()\n",
    "cov = MinCovDet().fit(train_data_norm)\n",
    "end_time = time()\n",
    "print(f\"Time elapsed: {(end_time - start_time)/60} minutes\")\n",
    "covariance = cov.covariance_\n",
    "\n",
    "covariance = np.cov(train_data_norm, rowvar=False)\n",
    "\n",
    "# Covariance matrix power of -1\n",
    "covariance_pm1 = np.linalg.matrix_power(covariance, -1)\n",
    "\n",
    "# Center point\n",
    "centerpoint = np.mean(train_data_norm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distances between center point and \n",
    "distances = []\n",
    "for i, val in enumerate(train_data_norm):\n",
    "    p1 = val\n",
    "    p2 = centerpoint\n",
    "    distance = (p1-p2).T.dot(covariance_pm1).dot(p1-p2)\n",
    "    distances.append(distance)\n",
    "distances = np.array(distances)\n",
    "\n",
    "# Cutoff (threshold) value from Chi-Sqaure Distribution for detecting outliers \n",
    "cutoff_threshold = 0.99\n",
    "cutoff = chi2.ppf(cutoff_threshold, train_data_norm.shape[1])\n",
    "\n",
    "# Index of outliers\n",
    "outlierIndexes = np.where(distances > cutoff)\n",
    "\n",
    "print('--- Index of Outliers ----')\n",
    "print(outlierIndexes)\n",
    "print(f\"There are {len(outlierIndexes[0])} outliers identified\")\n",
    "\n",
    "print('--- Observations found as outlier -----')\n",
    "print(train_data_norm[distances > cutoff, :])\n",
    "\n",
    "train_data_norm = np.delete(train_data_norm, outlierIndexes, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b3abc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d0de86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2879cdbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8342416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bb8b713",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0033e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_dim = 2\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(latent_space_dim,), mean=0., stddev=1.) # stddev is set to 0.1 in this post: https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "    return_value = z_mean + K.exp(z_log_sigma) * epsilon\n",
    "    #print(z_mean)\n",
    "    \n",
    "    return return_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad4437c",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8279e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((6,))\n",
    "layer1 = Dense(6, activation = 'relu')(inputs)\n",
    "layer2 = Dense(200, activation = 'relu')(layer1) # Changed from 3\n",
    "layer3 = Dense(100, activation = 'relu')(layer2) # Changed from 3\n",
    "layer4 = Dense(60, activation = 'relu')(layer3)\n",
    "layer5 = Dense(30, activation = 'relu')(layer4)\n",
    "z_mean = Dense(latent_space_dim)(layer5)\n",
    "z_log_sigma = Dense(latent_space_dim)(layer5)\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_sigma], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9099e7",
   "metadata": {},
   "source": [
    "### Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc8098",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_input1 = keras.Input(shape=(latent_space_dim,))\n",
    "sampler_input2 = keras.Input(shape=(latent_space_dim,))\n",
    "latent_sample = Lambda(sampling, output_shape = (latent_space_dim,))([sampler_input1, sampler_input2])\n",
    "sampler = keras.Model([sampler_input1, sampler_input2], latent_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7804bf1",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cf6b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_space_dim,))\n",
    "layer6 = Dense(20, activation = 'relu')(latent_inputs)\n",
    "layer7 = Dense(30, activation = 'relu')(layer6)\n",
    "layer8 = Dense(50, activation = 'relu')(layer7)\n",
    "layer9 = Dense(100, activation = 'relu')(layer8)\n",
    "layer10 = Dense(200, activation = 'relu')(layer9)\n",
    "decoder_outputs = Dense(6, activation = 'sigmoid')(layer10)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1508701b",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f9e962",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "    def __init__(self, encoder, sampler, decoder, beta = 1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.sampler = sampler\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_sigma = self.encoder(data)\n",
    "            z_log_var = 2 * z_log_sigma\n",
    "            z = self.sampler([z_mean, z_log_var])\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    def test_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            #print(f\"Ran. data: {data}\")\n",
    "            data = data[0]\n",
    "\n",
    "        z_mean, z_log_sigma = self.encoder(data)\n",
    "        z_log_var = 2 * z_log_sigma\n",
    "        z = self.sampler([z_mean, z_log_var])\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(kl_loss)\n",
    "        total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def call(self, data):\n",
    "        z_mean, z_log_sigma = self.encoder(data)\n",
    "        z_log_var = 2 * z_log_sigma\n",
    "        z = self.sampler([z_mean, z_log_var])\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(kl_loss)\n",
    "        total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        self.add_metric(kl_loss, name='kl_loss', aggregation='mean')\n",
    "        self.add_metric(total_loss, name='total_loss', aggregation='mean')\n",
    "        self.add_metric(reconstruction_loss, name='reconstruction_loss', aggregation='mean')\n",
    "        return reconstruction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deded5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, sampler, decoder, beta = 0.01)\n",
    "vae.compile(optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79db1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "history = vae.fit(x = train_data_norm, y = train_data_norm, # Changed from train_data_norm \n",
    "                  epochs = 1000,\n",
    "                  shuffle = True,\n",
    "                  batch_size = 32,\n",
    "                  workers = 8,\n",
    "                  validation_data = (valid_data_norm, valid_data_norm), # Changed from valid_data_norm\n",
    "                  callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedf11a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label = 'Training Loss')\n",
    "plt.plot(history.history['val_loss'], label = 'Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ea548",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = vae.predict(train_data_norm)\n",
    "test_predictions = vae.predict(test_data_norm)\n",
    "valid_predictions = vae.predict(valid_data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6686659",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"vae_fixed_loss_beta_0_01\"\n",
    "#os.chdir(\"C:/Users/ernest.liu/Documents/git/Morphine-22-23/ML/Model/weights/\")\n",
    "#vae.save_weights(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0c62db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training MAE: {np.sum(np.abs(train_data_norm - train_predictions))/(train_data_norm.shape[0] * train_data_norm.shape[1])}\")\n",
    "print(f\"Testing MAE (Anomalous Data): {np.sum(np.abs(test_data_norm - test_predictions))/(test_data_norm.shape[0] * test_data_norm.shape[1])}\")\n",
    "print(f\"Validation MAE (Normal Data): {np.sum(np.abs(valid_data_norm - valid_predictions))/(valid_data_norm.shape[0] * valid_data_norm.shape[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2186634",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mae = np.sum(np.abs(train_data_norm - train_predictions), axis = 1)\n",
    "plt.hist(train_mae, bins = 20)\n",
    "plt.title(\"Training Dataset\")\n",
    "plt.xlabel(\"Reconstruction Error (MAE)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d99ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_mae = np.sum(np.abs(valid_data_norm - valid_predictions), axis = 1)\n",
    "plt.hist(valid_mae, bins = 20)\n",
    "plt.title(\"Validation (Normal Samples) Dataset\")\n",
    "plt.xlabel(\"Reconstruction Error (MAE)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995dbc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae = np.sum(np.abs(test_data_norm - test_predictions), axis = 1)\n",
    "plt.hist(test_mae, bins = 20)\n",
    "plt.title(\"Testing (Anomalous) Dataset\")\n",
    "plt.xlabel(\"Reconstruction Error (MAE)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e64acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold = np.quantile(valid_mae, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ea2963",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110df665",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"mae\"] = np.sum(np.abs(scaler.transform(train_data) - vae.predict(scaler.transform(train_data))), axis = 1)\n",
    "train_data[\"is_anomalous\"] = train_data.mae > best_threshold\n",
    "\n",
    "test_data[\"mae\"] = test_mae\n",
    "test_data[\"is_anomalous\"] = test_mae > best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a807a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b18d59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test_data.index, test_data.mae, s = 0.2)\n",
    "plt.axhline(y=best_threshold, color='r', linestyle='-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0613ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_data.index, train_data.mae, s = 0.2)\n",
    "plt.axhline(y=best_threshold, color='r', linestyle='-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c1f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(test_data.is_anomalous)/test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34137a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(train_data.is_anomalous)/train_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff53e8",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c33529fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_dim = 2\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(latent_space_dim,), mean=0., stddev=1.) # stddev is set to 0.1 in this post: https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "    return_value = z_mean + K.exp(z_log_sigma) * epsilon\n",
    "    #print(z_mean)\n",
    "    \n",
    "    return return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56b34417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 6)            42          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 200)          1400        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 100)          20100       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 60)           6060        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 30)           1830        ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 2)            62          ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 2)            62          ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29,556\n",
      "Trainable params: 29,556\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input((6,))\n",
    "layer1 = Dense(6, activation = 'relu')(inputs)\n",
    "layer2 = Dense(200, activation = 'relu')(layer1) # Changed from 3\n",
    "layer3 = Dense(100, activation = 'relu')(layer2) # Changed from 3\n",
    "layer4 = Dense(60, activation = 'relu')(layer3)\n",
    "layer5 = Dense(30, activation = 'relu')(layer4)\n",
    "z_mean = Dense(latent_space_dim)(layer5)\n",
    "z_log_sigma = Dense(latent_space_dim)(layer5)\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_sigma], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55c2c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_input1 = keras.Input(shape=(latent_space_dim,))\n",
    "sampler_input2 = keras.Input(shape=(latent_space_dim,))\n",
    "latent_sample = Lambda(sampling, output_shape = (latent_space_dim,))([sampler_input1, sampler_input2])\n",
    "sampler = keras.Model([sampler_input1, sampler_input2], latent_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82494e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 20)                60        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 30)                630       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 50)                1550      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 6)                 1206      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,746\n",
      "Trainable params: 28,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_space_dim,))\n",
    "layer6 = Dense(20, activation = 'relu')(latent_inputs)\n",
    "layer7 = Dense(30, activation = 'relu')(layer6)\n",
    "layer8 = Dense(50, activation = 'relu')(layer7)\n",
    "layer9 = Dense(100, activation = 'relu')(layer8)\n",
    "layer10 = Dense(200, activation = 'relu')(layer9)\n",
    "decoder_outputs = Dense(6, activation = 'sigmoid')(layer10)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3350a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "    def __init__(self, encoder, sampler, decoder, beta = 1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.sampler = sampler\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_sigma = self.encoder(data)\n",
    "            z_log_var = 2 * z_log_sigma\n",
    "            z = self.sampler([z_mean, z_log_var])\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    def test_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            #print(f\"Ran. data: {data}\")\n",
    "            data = data[0]\n",
    "\n",
    "        z_mean, z_log_sigma = self.encoder(data)\n",
    "        z_log_var = 2 * z_log_sigma\n",
    "        z = self.sampler([z_mean, z_log_var])\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(kl_loss)\n",
    "        total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def call(self, data):\n",
    "        z_mean, z_log_sigma = self.encoder(data)\n",
    "        z_log_var = 2 * z_log_sigma\n",
    "        z = self.sampler([z_mean, z_log_var])\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(kl_loss)\n",
    "        total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        self.add_metric(kl_loss, name='kl_loss', aggregation='mean')\n",
    "        self.add_metric(total_loss, name='total_loss', aggregation='mean')\n",
    "        self.add_metric(reconstruction_loss, name='reconstruction_loss', aggregation='mean')\n",
    "        return reconstruction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34bd3cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, sampler, decoder, beta = 0.01)\n",
    "vae.compile(optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74da16be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1ca62fb3a60>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"C:/Users/ernest.liu/Documents/git/Morphine-22-23/ML/Model/weights/\")\n",
    "model_name = \"vae_fixed_loss_beta_0_01\"\n",
    "vae.load_weights(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d295b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516b59e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be0622f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0af01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
