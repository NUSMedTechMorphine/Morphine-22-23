{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "738e729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange\n",
    "from time import time\n",
    "\n",
    "from sklearn.covariance import MinCovDet\n",
    "from scipy.stats import chi2\n",
    "\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing, linear_model\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from sklearn.preprocessing import minmax_scale, OneHotEncoder\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Input, Dense, Reshape, Concatenate, Flatten, Lambda, Reshape, Dropout\n",
    "from keras.losses import MeanSquaredError as mse\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dfc24e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fall_simulation',\n",
       " 'fall_simulation2',\n",
       " 'fall_simulation3',\n",
       " 'fall_simulation_2.csv',\n",
       " 'fall_simulation_3.csv',\n",
       " 'trial_data_1',\n",
       " 'trial_data_1.csv',\n",
       " 'trial_data_2',\n",
       " 'trial_data_2.csv',\n",
       " 'trial_data_3',\n",
       " 'trial_data_3.csv',\n",
       " 'trial_data_4',\n",
       " 'trial_data_4.csv',\n",
       " 'trial_data_5',\n",
       " 'trial_data_5.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASETS_PATH = \"C:/Users/ernest.liu/Documents/git/Morphine-22-23/ML/Datasets/19-01-2023/\"\n",
    "os.chdir(DATASETS_PATH)\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf4816e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trial_data_1.csv', 'trial_data_2.csv', 'trial_data_3.csv', 'trial_data_4.csv', 'trial_data_5.csv']\n",
      "['fall_simulation_2.csv', 'fall_simulation_3.csv']\n"
     ]
    }
   ],
   "source": [
    "adl_files = [file_name for file_name in os.listdir() if \".csv\" in file_name and \"trial\" in file_name]\n",
    "fall_files = [file_name for file_name in os.listdir() if \".csv\" in file_name and \"fall\" in file_name]\n",
    "\n",
    "print(adl_files)\n",
    "print(fall_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd65722",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data_1 = pd.read_csv(DATASETS_PATH+'trial_data_1.csv').iloc[:,1:]\n",
    "trial_data_2 = pd.read_csv(DATASETS_PATH+'trial_data_2.csv').iloc[:,1:]\n",
    "trial_data_3 = pd.read_csv(DATASETS_PATH+'trial_data_3.csv').iloc[:,1:]\n",
    "trial_data_4 = pd.read_csv(DATASETS_PATH+'trial_data_4.csv').iloc[:,1:]\n",
    "trial_data_5 = pd.read_csv(DATASETS_PATH+'trial_data_5.csv').iloc[:,1:]\n",
    "\n",
    "fall_simulation_2 = pd.read_csv(DATASETS_PATH+'fall_simulation_2.csv').iloc[:,1:]\n",
    "fall_simulation_3 = pd.read_csv(DATASETS_PATH+'fall_simulation_3.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "189b1c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only take in accelerometer and gyroscope data\n",
    "trial_data_1 = trial_data_1[['Ax','Ay','Az','gx','gy','gz']]#.iloc[20:,:]\n",
    "trial_data_2 = trial_data_2[['Ax','Ay','Az','gx','gy','gz']]#.iloc[20:,:]\n",
    "trial_data_3 = trial_data_3[['Ax','Ay','Az','gx','gy','gz']]#.iloc[20:,:]\n",
    "trial_data_4 = trial_data_4[['Ax','Ay','Az','gx','gy','gz']]#.iloc[20:,:]\n",
    "trial_data_5 = trial_data_5[['Ax','Ay','Az','gx','gy','gz']]#.iloc[20:,:]\n",
    "\n",
    "fall_simulation_2 = fall_simulation_2[['Ax','Ay','Az','gx','gy','gz']]\n",
    "fall_simulation_3 = fall_simulation_3[['Ax','Ay','Az','gx','gy','gz']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63007455",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([trial_data_1, trial_data_2, trial_data_3, trial_data_4, trial_data_5]).reset_index(drop=True)\n",
    "test_data = pd.concat([fall_simulation_2, fall_simulation_3]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c8bf526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EDA\n",
    "plt.hist(np.abs(train_data.Ay), bins=100, alpha=0.5, density=True)\n",
    "plt.hist(np.abs(test_data.Ay), bins=100, alpha=0.5, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052b4278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d862209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e37a0e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7044129",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_norm_presplit = scaler.transform(train_data)\n",
    "test_data_norm = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da93a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ratio = 0.2\n",
    "valid_indices = sorted(random.sample(list(range(train_data_norm_presplit.shape[0])), round(train_data_norm_presplit.shape[0] * valid_ratio)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4601de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = train_data.iloc[valid_indices, :].reset_index(drop = True)\n",
    "valid_data_norm = train_data_norm_presplit[valid_indices]\n",
    "train_data_norm = np.delete(train_data_norm_presplit, valid_indices, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7677770b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106144, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50264422",
   "metadata": {},
   "source": [
    "## Mahalanobis Distance Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "881a3204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.42175363302230834 minutes\n"
     ]
    }
   ],
   "source": [
    "# Covariance matrix\n",
    "# covariance = np.cov(train_data, rowvar=False)\n",
    "\n",
    "start_time = time()\n",
    "cov = MinCovDet().fit(train_data_norm)\n",
    "end_time = time()\n",
    "print(f\"Time elapsed: {(end_time - start_time)/60} minutes\")\n",
    "covariance = cov.covariance_\n",
    "\n",
    "covariance = np.cov(train_data_norm, rowvar=False)\n",
    "\n",
    "# Covariance matrix power of -1\n",
    "covariance_pm1 = np.linalg.matrix_power(covariance, -1)\n",
    "\n",
    "# Center point\n",
    "centerpoint = np.mean(train_data_norm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ef4aaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Index of Outliers ----\n",
      "(array([  4405,   4406,   4407, ..., 105980, 105981, 105982], dtype=int64),)\n",
      "There are 4849 outliers identified\n",
      "--- Observations found as outlier -----\n",
      "[[0.4500255  0.48085901 0.31693014 1.         0.         0.40160183]\n",
      " [0.44849567 0.47338936 0.33426823 1.         0.         0.39816934]\n",
      " [0.44263131 0.47432306 0.30953595 1.         0.         0.39702517]\n",
      " ...\n",
      " [0.60963794 0.71848739 0.26160122 0.75514874 1.         0.35011442]\n",
      " [0.59433962 0.77404295 0.23916369 0.70480549 1.         0.34897025]\n",
      " [0.57623661 0.82913165 0.22131566 0.63844394 1.         0.35011442]]\n"
     ]
    }
   ],
   "source": [
    "# Distances between center point and \n",
    "distances = []\n",
    "for i, val in enumerate(train_data_norm):\n",
    "    p1 = val\n",
    "    p2 = centerpoint\n",
    "    distance = (p1-p2).T.dot(covariance_pm1).dot(p1-p2)\n",
    "    distances.append(distance)\n",
    "distances = np.array(distances)\n",
    "\n",
    "# Cutoff (threshold) value from Chi-Sqaure Distribution for detecting outliers \n",
    "cutoff_threshold = 0.99\n",
    "cutoff = chi2.ppf(cutoff_threshold, train_data_norm.shape[1])\n",
    "\n",
    "# Index of outliers\n",
    "outlierIndexes = np.where(distances > cutoff)\n",
    "\n",
    "print('--- Index of Outliers ----')\n",
    "print(outlierIndexes)\n",
    "print(f\"There are {len(outlierIndexes[0])} outliers identified\")\n",
    "\n",
    "print('--- Observations found as outlier -----')\n",
    "print(train_data_norm[distances > cutoff, :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d0de86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_norm = np.delete(train_data_norm, outlierIndexes, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2879cdbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8342416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bb8b713",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0033e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_dim = 2\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(latent_space_dim,), mean=0., stddev=1.) # stddev is set to 0.1 in this post: https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "    return_value = z_mean + K.exp(z_log_sigma) * epsilon\n",
    "    #print(z_mean)\n",
    "    \n",
    "    return return_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad4437c",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8279e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((6,))\n",
    "layer1 = Dense(6, activation = 'relu')(inputs)\n",
    "layer2 = Dense(200, activation = 'relu')(layer1) # Changed from 3\n",
    "layer3 = Dense(100, activation = 'relu')(layer2) # Changed from 3\n",
    "layer4 = Dense(60, activation = 'relu')(layer3)\n",
    "layer5 = Dense(30, activation = 'relu')(layer4)\n",
    "z_mean = Dense(latent_space_dim)(layer5)\n",
    "z_log_sigma = Dense(latent_space_dim)(layer5)\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_sigma], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9099e7",
   "metadata": {},
   "source": [
    "### Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc8098",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_input1 = keras.Input(shape=(latent_space_dim,))\n",
    "sampler_input2 = keras.Input(shape=(latent_space_dim,))\n",
    "latent_sample = Lambda(sampling, output_shape = (latent_space_dim,))([sampler_input1, sampler_input2])\n",
    "sampler = keras.Model([sampler_input1, sampler_input2], latent_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7804bf1",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cf6b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_space_dim,))\n",
    "layer6 = Dense(20, activation = 'relu')(latent_inputs)\n",
    "layer7 = Dense(30, activation = 'relu')(layer6)\n",
    "layer8 = Dense(50, activation = 'relu')(layer7)\n",
    "layer9 = Dense(100, activation = 'relu')(layer8)\n",
    "layer10 = Dense(200, activation = 'relu')(layer9)\n",
    "decoder_outputs = Dense(6, activation = 'sigmoid')(layer10)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1508701b",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f9e962",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "    def __init__(self, encoder, sampler, decoder, beta = 1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.sampler = sampler\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_sigma = self.encoder(data)\n",
    "            z_log_var = 2 * z_log_sigma\n",
    "            z = self.sampler([z_mean, z_log_var])\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    def test_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            #print(f\"Ran. data: {data}\")\n",
    "            data = data[0]\n",
    "\n",
    "        z_mean, z_log_sigma = self.encoder(data)\n",
    "        z_log_var = 2 * z_log_sigma\n",
    "        z = self.sampler([z_mean, z_log_var])\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(kl_loss)\n",
    "        total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def call(self, data):\n",
    "        z_mean, z_log_sigma = self.encoder(data)\n",
    "        z_log_var = 2 * z_log_sigma\n",
    "        z = self.sampler([z_mean, z_log_var])\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(kl_loss)\n",
    "        total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        self.add_metric(kl_loss, name='kl_loss', aggregation='mean')\n",
    "        self.add_metric(total_loss, name='total_loss', aggregation='mean')\n",
    "        self.add_metric(reconstruction_loss, name='reconstruction_loss', aggregation='mean')\n",
    "        return reconstruction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deded5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, sampler, decoder, beta = 0.01)\n",
    "vae.compile(optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79db1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "history = vae.fit(x = train_data_norm, y = train_data_norm, # Changed from train_data_norm \n",
    "                  epochs = 1000,\n",
    "                  shuffle = True,\n",
    "                  batch_size = 32,\n",
    "                  workers = 8,\n",
    "                  validation_data = (valid_data_norm, valid_data_norm), # Changed from valid_data_norm\n",
    "                  callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedf11a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label = 'Training Loss')\n",
    "plt.plot(history.history['val_loss'], label = 'Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ea548",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = vae.predict(train_data_norm)\n",
    "test_predictions = vae.predict(test_data_norm)\n",
    "valid_predictions = vae.predict(valid_data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6686659",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"vae_fixed_loss_beta_0_01\"\n",
    "# os.chdir(\"C:/Users/ernest.liu/Documents/git/Morphine-22-23/ML/Model/weights/\")\n",
    "# vae.save_weights(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0c62db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training MAE: {np.sum(np.abs(train_data_norm - train_predictions))/(train_data_norm.shape[0] * train_data_norm.shape[1])}\")\n",
    "print(f\"Testing MAE (Anomalous Data): {np.sum(np.abs(test_data_norm - test_predictions))/(test_data_norm.shape[0] * test_data_norm.shape[1])}\")\n",
    "print(f\"Validation MAE (Normal Data): {np.sum(np.abs(valid_data_norm - valid_predictions))/(valid_data_norm.shape[0] * valid_data_norm.shape[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2186634",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mae = np.sum(np.abs(train_data_norm - train_predictions), axis = 1)\n",
    "plt.hist(train_mae, bins = 20)\n",
    "plt.title(\"Training Dataset\")\n",
    "plt.xlabel(\"Reconstruction Error (MAE)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d99ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_mae = np.sum(np.abs(valid_data_norm - valid_predictions), axis = 1)\n",
    "plt.hist(valid_mae, bins = 20)\n",
    "plt.title(\"Validation (Normal Samples) Dataset\")\n",
    "plt.xlabel(\"Reconstruction Error (MAE)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995dbc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae = np.sum(np.abs(test_data_norm - test_predictions), axis = 1)\n",
    "plt.hist(test_mae, bins = 20)\n",
    "plt.title(\"Testing (Anomalous) Dataset\")\n",
    "plt.xlabel(\"Reconstruction Error (MAE)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e64acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold = np.quantile(valid_mae, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ea2963",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110df665",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"mae\"] = np.sum(np.abs(scaler.transform(train_data) - vae.predict(scaler.transform(train_data))), axis = 1)\n",
    "train_data[\"is_anomalous\"] = train_data.mae > best_threshold\n",
    "\n",
    "test_data[\"mae\"] = test_mae\n",
    "test_data[\"is_anomalous\"] = test_mae > best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a807a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b18d59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test_data.index, test_data.mae, s = 0.2)\n",
    "plt.axhline(y=best_threshold, color='r', linestyle='-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0613ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_data.index, train_data.mae, s = 0.2)\n",
    "plt.axhline(y=best_threshold, color='r', linestyle='-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c1f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(test_data.is_anomalous)/test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34137a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(train_data.is_anomalous)/train_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff53e8",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33529fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_dim = 2\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(latent_space_dim,), mean=0., stddev=1.) # stddev is set to 0.1 in this post: https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "    return_value = z_mean + K.exp(z_log_sigma) * epsilon\n",
    "    #print(z_mean)\n",
    "    \n",
    "    return return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b34417",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((6,))\n",
    "layer1 = Dense(6, activation = 'relu')(inputs)\n",
    "layer2 = Dense(200, activation = 'relu')(layer1) # Changed from 3\n",
    "layer3 = Dense(100, activation = 'relu')(layer2) # Changed from 3\n",
    "layer4 = Dense(60, activation = 'relu')(layer3)\n",
    "layer5 = Dense(30, activation = 'relu')(layer4)\n",
    "z_mean = Dense(latent_space_dim)(layer5)\n",
    "z_log_sigma = Dense(latent_space_dim)(layer5)\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_sigma], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c2c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_input1 = keras.Input(shape=(latent_space_dim,))\n",
    "sampler_input2 = keras.Input(shape=(latent_space_dim,))\n",
    "latent_sample = Lambda(sampling, output_shape = (latent_space_dim,))([sampler_input1, sampler_input2])\n",
    "sampler = keras.Model([sampler_input1, sampler_input2], latent_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82494e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_space_dim,))\n",
    "layer6 = Dense(20, activation = 'relu')(latent_inputs)\n",
    "layer7 = Dense(30, activation = 'relu')(layer6)\n",
    "layer8 = Dense(50, activation = 'relu')(layer7)\n",
    "layer9 = Dense(100, activation = 'relu')(layer8)\n",
    "layer10 = Dense(200, activation = 'relu')(layer9)\n",
    "decoder_outputs = Dense(6, activation = 'sigmoid')(layer10)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3350a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "    def __init__(self, encoder, sampler, decoder, beta = 1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.sampler = sampler\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_sigma = self.encoder(data)\n",
    "            z_log_var = 2 * z_log_sigma\n",
    "            z = self.sampler([z_mean, z_log_var])\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    def test_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            #print(f\"Ran. data: {data}\")\n",
    "            data = data[0]\n",
    "\n",
    "        z_mean, z_log_sigma = self.encoder(data)\n",
    "        z_log_var = 2 * z_log_sigma\n",
    "        z = self.sampler([z_mean, z_log_var])\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(kl_loss)\n",
    "        total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def call(self, data):\n",
    "        z_mean, z_log_sigma = self.encoder(data)\n",
    "        z_log_var = 2 * z_log_sigma\n",
    "        z = self.sampler([z_mean, z_log_var])\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(kl_loss)\n",
    "        total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        self.add_metric(kl_loss, name='kl_loss', aggregation='mean')\n",
    "        self.add_metric(total_loss, name='total_loss', aggregation='mean')\n",
    "        self.add_metric(reconstruction_loss, name='reconstruction_loss', aggregation='mean')\n",
    "        return reconstruction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd3cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, sampler, decoder, beta = 0.01)\n",
    "vae.compile(optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74da16be",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/ernest.liu/Documents/git/Morphine-22-23/ML/Model/weights/\")\n",
    "model_name = \"vae_fixed_loss_beta_0_01\"\n",
    "vae.load_weights(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = vae.predict(train_data_norm)\n",
    "test_predictions = vae.predict(test_data_norm)\n",
    "valid_predictions = vae.predict(valid_data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516b59e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_mae = np.sum(np.abs(valid_data_norm - valid_predictions), axis = 1)\n",
    "best_threshold = np.quantile(valid_mae, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be0622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0af01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d03cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8c21c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c052e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(scaler, open('scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41060f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3161d2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac8306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f90a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa016c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90aa63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4221d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b07014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a7408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/ernest.liu/Documents/git/Morphine-22-23/ML/Docker/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11cd896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import db\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Connection to Firebase\n",
    "cred_obj = firebase_admin.credentials.Certificate(\"../Morphine2.json\")\n",
    "default_app = firebase_admin.initialize_app(cred_obj, {\n",
    "  'databaseURL':'https://morphine-64cdd-default-rtdb.asia-southeast1.firebasedatabase.app/'\n",
    "  })\n",
    "USERS_DATA = db.reference(\"/Users Data/Token UID:XvIeVwC7M0QN0qW15FNYO2e5BJ93\")\n",
    "FIREBASE_PREDICTION_PATH = db.reference(\"/Users Data/Token UID:XvIeVwC7M0QN0qW15FNYO2e5BJ93/Split Circuit/MPU6050/MPU6050 Fall/\")\n",
    "\n",
    "# Process GPS Data\n",
    "GPS_KEYWORDS_LIST = ['Latitude: ', '(*10^-7) Longitude: ', '(*10^-7) Altitude: ', '(mm) Satellite-in-view: ', 'timing for this set: ']\n",
    "GPS_KEYWORDS_LENGTH = [len(keyword) for keyword in GPS_KEYWORDS_LIST]\n",
    "\n",
    "def process_gps_datapoints(gps_datapoints):\n",
    "    \"\"\"\n",
    "    gps_datapoints = gps_data['GPS Datapoints']\n",
    "    \"\"\"\n",
    "    gps_datapoints = gps_datapoints[0]\n",
    "    indices = [gps_datapoints.find(keyword) for keyword in GPS_KEYWORDS_LIST]\n",
    "    # Latitude, Longtiude, Altitude, Satellite-in-view, timing for this set\n",
    "    gps_datapoints_list = []\n",
    "    for i, index in enumerate(indices):\n",
    "        if i == len(indices) - 1:\n",
    "            gps_datapoints_list.append(float(gps_datapoints[index + GPS_KEYWORDS_LENGTH[i]:].strip()))\n",
    "        else:\n",
    "            gps_datapoints_list.append(float(gps_datapoints[index + GPS_KEYWORDS_LENGTH[i]:indices[i+1]].strip()))\n",
    "    return gps_datapoints_list\n",
    "\n",
    "def process_gps(gps):\n",
    "    \"\"\"\n",
    "    gps = data['Split Circuit']['GPS']\n",
    "    \"\"\"\n",
    "    processed_gps_data = []\n",
    "    gps_accounter = gps['GPS Accounter']\n",
    "    gps_datapoints = gps['GPS Datapoints']\n",
    "    gps_loopSpeedArr = gps['GPS LoopSpeedArr'][0]\n",
    "    gps_uploadSpeedArr = gps['GPS UploadSpeedArr'][0]\n",
    "    \n",
    "    processed_gps_datapoints = process_gps_datapoints(gps_datapoints)\n",
    "    \n",
    "    processed_gps_data.append(gps_accounter)\n",
    "    processed_gps_data.extend(processed_gps_datapoints)\n",
    "    processed_gps_data.extend([gps_loopSpeedArr, gps_uploadSpeedArr])\n",
    "    \n",
    "    new_gps_df = pd.DataFrame([processed_gps_data],\n",
    "                             columns = ['accounter', 'latitude', 'longitude', 'altitude', 'satelliteInView', 'timingForThisSet', 'LoopSpeed', 'UploadSpeed'])\n",
    "    return new_gps_df\n",
    "\n",
    "# process MPU6050\n",
    "MPU6050_KEYWORDS = ['Ax: ', 'Ay: ', 'Az: ', 'gx: ', 'gy: ', 'gz: ', 'temp: ', 'timing for this set: ']\n",
    "MPU6050_KEYWORDS_LENGTH = [len(x) for x in MPU6050_KEYWORDS]\n",
    "\n",
    "## function to process one datapoint\n",
    "def process_one_set_of_datapoint(output_set):\n",
    "    indexes = [output_set.find(keyword) for keyword in MPU6050_KEYWORDS]\n",
    "    df_row = []\n",
    "    curr_data_index = int(output_set[:indexes[0]].strip())\n",
    "    df_row.append(curr_data_index) # append in the index of the new input\n",
    "    for i, index in enumerate(indexes):\n",
    "        if i == len(indexes) - 1:\n",
    "            x = float(output_set[index+MPU6050_KEYWORDS_LENGTH[i]:].strip())\n",
    "            df_row.append(x)\n",
    "        else:\n",
    "            x = float(output_set[index+MPU6050_KEYWORDS_LENGTH[i]: indexes[i+1]].strip())\n",
    "            df_row.append(x)\n",
    "    return df_row\n",
    "\n",
    "def process_mpu6050(mpu6050, timeDifference):\n",
    "    \"\"\"\n",
    "    mpu6050_output = split_circuit_data['MPU6050']\n",
    "    \"\"\"\n",
    "    mpu6050_df = pd.DataFrame(columns = ['accounter', 'LoopSpeedArr', 'UploadSpeedArr', 'set_index', 'Ax', 'Ay', 'Az', 'gx', 'gy', 'gz', 'temp', 'timingForThisSet', 'timeDifference'])\n",
    "    accounter = mpu6050['MPU6050 Accounter']\n",
    "    mpu6050_datapoints = mpu6050['MPU6050 Datapoints'][0]\n",
    "    mpu6050_loopSpeedArr = mpu6050['MPU6050 LoopSpeedArr'][0]\n",
    "    mpu6050_uploadSpeedArr = mpu6050['MPU6050 UploadSpeedArr'][0]\n",
    "    mpu6050_output_sets = mpu6050_datapoints.split('Set: ')[1:]\n",
    "    \n",
    "    for output in mpu6050_output_sets:\n",
    "        data = [accounter, mpu6050_loopSpeedArr,mpu6050_uploadSpeedArr]\n",
    "        datapoint = process_one_set_of_datapoint(output)\n",
    "        data.extend(datapoint)\n",
    "        data.append(timeDifference)\n",
    "        new_df = pd.DataFrame([data], \n",
    "                              columns = ['accounter', 'LoopSpeedArr', 'UploadSpeedArr', 'set_index', 'Ax', 'Ay', 'Az', 'gx', 'gy', 'gz', 'temp', 'timingForThisSet', 'timeDifference'])\n",
    "        mpu6050_df = pd.concat([mpu6050_df, new_df], ignore_index = True)\n",
    "    return mpu6050_df\n",
    "\n",
    "# overall function to read split circuit\n",
    "def process_split_ciruit_data(split_circuit_data):\n",
    "    \"\"\"\n",
    "    split_circuit_data = data['Split Circuit']\n",
    "    \"\"\"\n",
    "    gps_df = pd.DataFrame(columns = ['accounter', 'latitude', 'longitude', 'altitude', 'satelliteInView', 'timingForThisSet', 'LoopSpeed', 'UploadSpeed'])\n",
    "    mpu6050_df = pd.DataFrame(columns = ['accounter', 'LoopSpeedArr', 'UploadSpeedArr', 'set_index', 'Ax', 'Ay', 'Az', 'gx', 'gy', 'gz', 'temp', 'timingForThisSet', 'timeDifference'])\n",
    "\n",
    "    keys = split_circuit_data.keys()\n",
    "    for key in keys:\n",
    "        if key == 'GPS':\n",
    "            gps_data = split_circuit_data['GPS']\n",
    "            processed_gps_data = process_gps(gps_data)\n",
    "            gps_df = pd.concat([gps_df, processed_gps_data])\n",
    "            print('Extracted GPS Data')\n",
    "            \n",
    "        elif key == 'GPS Button':\n",
    "            print(\"GPS Button:\", split_circuit_data['GPS Button'])\n",
    "            \n",
    "        elif key == 'MPU6050':\n",
    "            mpu6050_output = split_circuit_data['MPU6050']\n",
    "            processed_mpu6050_output = process_mpu6050(mpu6050_output, None)\n",
    "            mpu6050_df = pd.concat([mpu6050_df, processed_mpu6050_output])\n",
    "            print('Extracted MPU6050 Data')\n",
    "    return gps_df, mpu6050_df\n",
    "\n",
    "# MAIN FUNCTION to read data from Google Firebase\n",
    "def read_data():\n",
    "    data = USERS_DATA.get()\n",
    "    split_circuit_data = data['Split Circuit']\n",
    "    gps_df, mpu6050_df = process_split_ciruit_data(split_circuit_data)\n",
    "    return gps_df, mpu6050_df\n",
    "\n",
    "def predict(wave_data, t1=8.6396, t2=0.5):\n",
    "    \"\"\"\n",
    "    Actual:\n",
    "    This function make use of the autoencoder model to predict one wave of data - 20 datapoints.\n",
    "    The model will predict whether each of this 20 datapoints is ADL or Fall from the reconstruction error threshold, t1.\n",
    "    If the number of datapoints in a wave is more than a certain threshold, t2, we will then classify it as Fall, else ADL.\n",
    "\n",
    "    For now:\n",
    "    t1 is threshold to classify one datapoint based on the y-axis of accelerometer \n",
    "    t2 is threshold to classify a wave - 0.5 i.e. if >= 50% of the datapoints are anomalous, this wave will be classified as fall\n",
    "    \"\"\"\n",
    "    return np.sum(np.abs(wave_data.Ay) > t1) >= t2 * wave_data.shape[0]\n",
    "\n",
    "def write_to_firebase(prediction, prediction_path=FIREBASE_PREDICTION_PATH):\n",
    "    \"\"\" Write results to firebase \"\"\"\n",
    "    if prediction.lower() == \"fall detected\":\n",
    "        prediction_path.update({\"0\":\"Fall Detected\"})\n",
    "    elif prediction.lower() == \"normal\":\n",
    "        prediction_path.update({\"0\":\"Normal\"})\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     while True:\n",
    "#         gps_df, mpu6050_df = read_data()\n",
    "#         print(\"GPS and MPU6050 Dataframe Shape:\", gps_df.shape, mpu6050_df.shape)\n",
    "#         # prediction = predict(wave_data=mpu6050_df.values)\n",
    "#         prediction = \"Fall detected\"\n",
    "#         print(\"Prediction:\", prediction.title())\n",
    "#         # write_to_firebase(prediction)\n",
    "#         print(\"Updated Firebase!\")\n",
    "#         print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76da305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_df, mpu6050_df = read_data()\n",
    "test_data = read_data()[1][[\"Ax\", \"Ay\", \"Az\", \"gx\", \"gy\", \"gz\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de79c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337dcdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cafd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf1ca1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c689d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79bbff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
